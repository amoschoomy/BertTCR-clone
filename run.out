
Starting BertTCR prediction script...

Arguments:
sample_dir: /scratch/project/tcr_ml/BertTCR/phs002517_embedding
model_file: /scratch/project/tcr_ml/BertTCR/TrainedModels/Pretrained_multiple_cancer_detection.pth
tcr_num: 100
max_length: 24
kernel_size: [2, 3, 4]
filter_num: [3, 2, 1]
dropout: 0.4
device: cuda:0
output: ./phs002517_prediction.tsv

Loading model...
Initializing BertTCR with parameters:
filter_num: [3, 2, 1]
kernel_size: [2, 3, 4]
ins_num: 100
drop_out: 0.4
Model loaded successfully

Starting prediction...

Processing sample: TRUST_19d2f9a5-9e31-4bbd-965b-7bb4d3b8a53d_airr_extracted_trb_frequencies_filtered.tsv_batch_10_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7111528338840476
Prediction: True

Processing sample: TRUST_e18195a1-f04d-4270-ac12-6b4e3accf8a1_airr_extracted_trb_frequencies_filtered.tsv_batch_3_embedding.pt
Loaded sample shape: torch.Size([97, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([97, 23, 768])
Input matrix size: 1713408

Making prediction...
Original input shape: torch.Size([97, 23, 768])
Shape after padding: torch.Size([97, 24, 768])
Shape after permute: torch.Size([97, 768, 24])
Shapes after individual convolutions: [torch.Size([97, 3, 1]), torch.Size([97, 2, 1]), torch.Size([97, 1, 1])]
Shape after concatenation: torch.Size([97, 6, 1])
Shape after first reshape: torch.Size([97, 1, 6])
Shape after FC layer and dropout: torch.Size([97, 1, 1])
Shape before final padding: torch.Size([97])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.35353876497114095
Prediction: False

Processing sample: TRUST_5fca4dd7-67ae-4866-bf38-97bb51968b50_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([33, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([33, 20, 768])
Input matrix size: 506880

Making prediction...
Original input shape: torch.Size([33, 20, 768])
Shape after padding: torch.Size([33, 24, 768])
Shape after permute: torch.Size([33, 768, 24])
Shapes after individual convolutions: [torch.Size([33, 3, 1]), torch.Size([33, 2, 1]), torch.Size([33, 1, 1])]
Shape after concatenation: torch.Size([33, 6, 1])
Shape after first reshape: torch.Size([33, 1, 6])
Shape after FC layer and dropout: torch.Size([33, 1, 1])
Shape before final padding: torch.Size([33])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6186108390562046
Prediction: True

Processing sample: TRUST_85c32448-efc6-44ef-9fad-3b3403203843_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([82, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([82, 20, 768])
Input matrix size: 1259520

Making prediction...
Original input shape: torch.Size([82, 20, 768])
Shape after padding: torch.Size([82, 24, 768])
Shape after permute: torch.Size([82, 768, 24])
Shapes after individual convolutions: [torch.Size([82, 3, 1]), torch.Size([82, 2, 1]), torch.Size([82, 1, 1])]
Shape after concatenation: torch.Size([82, 6, 1])
Shape after first reshape: torch.Size([82, 1, 6])
Shape after FC layer and dropout: torch.Size([82, 1, 1])
Shape before final padding: torch.Size([82])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6711517643842777
Prediction: True

Processing sample: TRUST_3fb80c81-1475-4374-9694-fad58489a197_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([35, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([35, 22, 768])
Input matrix size: 591360

Making prediction...
Original input shape: torch.Size([35, 22, 768])
Shape after padding: torch.Size([35, 24, 768])
Shape after permute: torch.Size([35, 768, 24])
Shapes after individual convolutions: [torch.Size([35, 3, 1]), torch.Size([35, 2, 1]), torch.Size([35, 1, 1])]
Shape after concatenation: torch.Size([35, 6, 1])
Shape after first reshape: torch.Size([35, 1, 6])
Shape after FC layer and dropout: torch.Size([35, 1, 1])
Shape before final padding: torch.Size([35])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.45948802509263376
Prediction: False

Processing sample: TRUST_222cfdc4-1961-4cec-bc7c-7ae15c004179_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([30, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([30, 20, 768])
Input matrix size: 460800

Making prediction...
Original input shape: torch.Size([30, 20, 768])
Shape after padding: torch.Size([30, 24, 768])
Shape after permute: torch.Size([30, 768, 24])
Shapes after individual convolutions: [torch.Size([30, 3, 1]), torch.Size([30, 2, 1]), torch.Size([30, 1, 1])]
Shape after concatenation: torch.Size([30, 6, 1])
Shape after first reshape: torch.Size([30, 1, 6])
Shape after FC layer and dropout: torch.Size([30, 1, 1])
Shape before final padding: torch.Size([30])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5182320666841671
Prediction: True

Processing sample: TRUST_31b54a81-2aa5-4f6b-b3c8-902dfb0cad00_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([25, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([25, 20, 768])
Input matrix size: 384000

Making prediction...
Original input shape: torch.Size([25, 20, 768])
Shape after padding: torch.Size([25, 24, 768])
Shape after permute: torch.Size([25, 768, 24])
Shapes after individual convolutions: [torch.Size([25, 3, 1]), torch.Size([25, 2, 1]), torch.Size([25, 1, 1])]
Shape after concatenation: torch.Size([25, 6, 1])
Shape after first reshape: torch.Size([25, 1, 6])
Shape after FC layer and dropout: torch.Size([25, 1, 1])
Shape before final padding: torch.Size([25])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5467851084426373
Prediction: True

Processing sample: TRUST_3b3b490d-1dd6-40b8-8847-34ff630e159d_airr_extracted_trb_frequencies_filtered.tsv_batch_7_embedding.pt
Loaded sample shape: torch.Size([100, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 23, 768])
Input matrix size: 1766400

Making prediction...
Original input shape: torch.Size([100, 23, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6931484041843515
Prediction: True

Processing sample: TRUST_9e703f89-8102-4509-b42b-8911453c514c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([80, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([80, 21, 768])
Input matrix size: 1290240

Making prediction...
Original input shape: torch.Size([80, 21, 768])
Shape after padding: torch.Size([80, 24, 768])
Shape after permute: torch.Size([80, 768, 24])
Shapes after individual convolutions: [torch.Size([80, 3, 1]), torch.Size([80, 2, 1]), torch.Size([80, 1, 1])]
Shape after concatenation: torch.Size([80, 6, 1])
Shape after first reshape: torch.Size([80, 1, 6])
Shape after FC layer and dropout: torch.Size([80, 1, 1])
Shape before final padding: torch.Size([80])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.43832999748987256
Prediction: False

Processing sample: TRUST_19d2f9a5-9e31-4bbd-965b-7bb4d3b8a53d_airr_extracted_trb_frequencies_filtered.tsv_batch_8_embedding.pt
Loaded sample shape: torch.Size([100, 24, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 24, 768])
Input matrix size: 1843200

Making prediction...
Original input shape: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7042499409515829
Prediction: True

Processing sample: TRUST_f247c909-3278-4b1e-983f-833276dc8be0_airr_extracted_trb_frequencies_filtered.tsv_batch_4_embedding.pt
Loaded sample shape: torch.Size([61, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([61, 21, 768])
Input matrix size: 983808

Making prediction...
Original input shape: torch.Size([61, 21, 768])
Shape after padding: torch.Size([61, 24, 768])
Shape after permute: torch.Size([61, 768, 24])
Shapes after individual convolutions: [torch.Size([61, 3, 1]), torch.Size([61, 2, 1]), torch.Size([61, 1, 1])]
Shape after concatenation: torch.Size([61, 6, 1])
Shape after first reshape: torch.Size([61, 1, 6])
Shape after FC layer and dropout: torch.Size([61, 1, 1])
Shape before final padding: torch.Size([61])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5945619901319766
Prediction: True

Processing sample: TRUST_f247c909-3278-4b1e-983f-833276dc8be0_airr_extracted_trb_frequencies_filtered.tsv_batch_3_embedding.pt
Loaded sample shape: torch.Size([100, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 23, 768])
Input matrix size: 1766400

Making prediction...
Original input shape: torch.Size([100, 23, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5077592386899911
Prediction: True

Processing sample: TRUST_10920d36-d1f9-4dec-88be-4ef4c87c7a79_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([29, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([29, 20, 768])
Input matrix size: 445440

Making prediction...
Original input shape: torch.Size([29, 20, 768])
Shape after padding: torch.Size([29, 24, 768])
Shape after permute: torch.Size([29, 768, 24])
Shapes after individual convolutions: [torch.Size([29, 3, 1]), torch.Size([29, 2, 1]), torch.Size([29, 1, 1])]
Shape after concatenation: torch.Size([29, 6, 1])
Shape after first reshape: torch.Size([29, 1, 6])
Shape after FC layer and dropout: torch.Size([29, 1, 1])
Shape before final padding: torch.Size([29])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5062581385248196
Prediction: True

Processing sample: TRUST_3b3b490d-1dd6-40b8-8847-34ff630e159d_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([100, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 20, 768])
Input matrix size: 1536000

Making prediction...
Original input shape: torch.Size([100, 20, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6432655579926334
Prediction: True

Processing sample: TRUST_e28fa0f9-db56-4c16-a6d6-15f8751e11cd_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([10, 24, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([10, 24, 768])
Input matrix size: 184320

Making prediction...
Original input shape: torch.Size([10, 24, 768])
Shape after permute: torch.Size([10, 768, 24])
Shapes after individual convolutions: [torch.Size([10, 3, 1]), torch.Size([10, 2, 1]), torch.Size([10, 1, 1])]
Shape after concatenation: torch.Size([10, 6, 1])
Shape after first reshape: torch.Size([10, 1, 6])
Shape after FC layer and dropout: torch.Size([10, 1, 1])
Shape before final padding: torch.Size([10])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5190186117117055
Prediction: True

Processing sample: TRUST_80483dae-3f79-4a84-95da-e52862c117f4_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([70, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([70, 21, 768])
Input matrix size: 1128960

Making prediction...
Original input shape: torch.Size([70, 21, 768])
Shape after padding: torch.Size([70, 24, 768])
Shape after permute: torch.Size([70, 768, 24])
Shapes after individual convolutions: [torch.Size([70, 3, 1]), torch.Size([70, 2, 1]), torch.Size([70, 1, 1])]
Shape after concatenation: torch.Size([70, 6, 1])
Shape after first reshape: torch.Size([70, 1, 6])
Shape after FC layer and dropout: torch.Size([70, 1, 1])
Shape before final padding: torch.Size([70])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5624637476620445
Prediction: True

Processing sample: TRUST_65854bfb-5d68-4d10-85d5-d2e1459da8f6_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 24, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 24, 768])
Input matrix size: 1843200

Making prediction...
Original input shape: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5837498414123083
Prediction: True

Processing sample: TRUST_b50c95cc-4acf-4a72-a49a-32b9e408c19e_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([45, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([45, 21, 768])
Input matrix size: 725760

Making prediction...
Original input shape: torch.Size([45, 21, 768])
Shape after padding: torch.Size([45, 24, 768])
Shape after permute: torch.Size([45, 768, 24])
Shapes after individual convolutions: [torch.Size([45, 3, 1]), torch.Size([45, 2, 1]), torch.Size([45, 1, 1])]
Shape after concatenation: torch.Size([45, 6, 1])
Shape after first reshape: torch.Size([45, 1, 6])
Shape after FC layer and dropout: torch.Size([45, 1, 1])
Shape before final padding: torch.Size([45])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5294793605799998
Prediction: True

Processing sample: TRUST_4c4d16d6-9159-451c-997a-65873bd20d95_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([32, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([32, 21, 768])
Input matrix size: 516096

Making prediction...
Original input shape: torch.Size([32, 21, 768])
Shape after padding: torch.Size([32, 24, 768])
Shape after permute: torch.Size([32, 768, 24])
Shapes after individual convolutions: [torch.Size([32, 3, 1]), torch.Size([32, 2, 1]), torch.Size([32, 1, 1])]
Shape after concatenation: torch.Size([32, 6, 1])
Shape after first reshape: torch.Size([32, 1, 6])
Shape after FC layer and dropout: torch.Size([32, 1, 1])
Shape before final padding: torch.Size([32])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4804996864494839
Prediction: False

Processing sample: TRUST_466b4b32-6823-4c8f-9166-2465d8c34e59_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([52, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([52, 26, 768])
Input matrix size: 1038336

Making prediction...
Original input shape: torch.Size([52, 26, 768])
Shape after permute: torch.Size([52, 768, 26])
Shapes after individual convolutions: [torch.Size([52, 3, 1]), torch.Size([52, 2, 1]), torch.Size([52, 1, 1])]
Shape after concatenation: torch.Size([52, 6, 1])
Shape after first reshape: torch.Size([52, 1, 6])
Shape after FC layer and dropout: torch.Size([52, 1, 1])
Shape before final padding: torch.Size([52])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6468001866822077
Prediction: True

Processing sample: TRUST_865fe9ae-2260-42c1-bb54-0294811bbfb7_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([50, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([50, 26, 768])
Input matrix size: 998400

Making prediction...
Original input shape: torch.Size([50, 26, 768])
Shape after permute: torch.Size([50, 768, 26])
Shapes after individual convolutions: [torch.Size([50, 3, 1]), torch.Size([50, 2, 1]), torch.Size([50, 1, 1])]
Shape after concatenation: torch.Size([50, 6, 1])
Shape after first reshape: torch.Size([50, 1, 6])
Shape after FC layer and dropout: torch.Size([50, 1, 1])
Shape before final padding: torch.Size([50])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.45668932624065584
Prediction: False

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_26_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6542068402707014
Prediction: True

Processing sample: TRUST_19125545-fdad-411d-a389-c1820979e947_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 23, 768])
Input matrix size: 1766400

Making prediction...
Original input shape: torch.Size([100, 23, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7088439552013559
Prediction: True

Processing sample: TRUST_1c13b4a2-4617-404c-9beb-c30441f3d294_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([30, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([30, 19, 768])
Input matrix size: 437760

Making prediction...
Original input shape: torch.Size([30, 19, 768])
Shape after padding: torch.Size([30, 24, 768])
Shape after permute: torch.Size([30, 768, 24])
Shapes after individual convolutions: [torch.Size([30, 3, 1]), torch.Size([30, 2, 1]), torch.Size([30, 1, 1])]
Shape after concatenation: torch.Size([30, 6, 1])
Shape after first reshape: torch.Size([30, 1, 6])
Shape after FC layer and dropout: torch.Size([30, 1, 1])
Shape before final padding: torch.Size([30])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.36683114460997546
Prediction: False

Processing sample: TRUST_e9ce0471-bc67-47b2-9e60-886345454300_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([90, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([90, 22, 768])
Input matrix size: 1520640

Making prediction...
Original input shape: torch.Size([90, 22, 768])
Shape after padding: torch.Size([90, 24, 768])
Shape after permute: torch.Size([90, 768, 24])
Shapes after individual convolutions: [torch.Size([90, 3, 1]), torch.Size([90, 2, 1]), torch.Size([90, 1, 1])]
Shape after concatenation: torch.Size([90, 6, 1])
Shape after first reshape: torch.Size([90, 1, 6])
Shape after FC layer and dropout: torch.Size([90, 1, 1])
Shape before final padding: torch.Size([90])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6587055759351592
Prediction: True

Processing sample: TRUST_fb8d4b28-ea5e-47cb-8465-08a475d9bfb1_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([81, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([81, 22, 768])
Input matrix size: 1368576

Making prediction...
Original input shape: torch.Size([81, 22, 768])
Shape after padding: torch.Size([81, 24, 768])
Shape after permute: torch.Size([81, 768, 24])
Shapes after individual convolutions: [torch.Size([81, 3, 1]), torch.Size([81, 2, 1]), torch.Size([81, 1, 1])]
Shape after concatenation: torch.Size([81, 6, 1])
Shape after first reshape: torch.Size([81, 1, 6])
Shape after FC layer and dropout: torch.Size([81, 1, 1])
Shape before final padding: torch.Size([81])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6427492747035346
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_33_embedding.pt
Loaded sample shape: torch.Size([100, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 23, 768])
Input matrix size: 1766400

Making prediction...
Original input shape: torch.Size([100, 23, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4122827936594484
Prediction: False

Processing sample: TRUST_0c8cd4ea-8477-4e76-9d82-02be4bf16141_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 24, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 24, 768])
Input matrix size: 1843200

Making prediction...
Original input shape: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6314333402014065
Prediction: True

Processing sample: TRUST_85676a7b-9e93-444d-b76c-e110db80876c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([44, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([44, 21, 768])
Input matrix size: 709632

Making prediction...
Original input shape: torch.Size([44, 21, 768])
Shape after padding: torch.Size([44, 24, 768])
Shape after permute: torch.Size([44, 768, 24])
Shapes after individual convolutions: [torch.Size([44, 3, 1]), torch.Size([44, 2, 1]), torch.Size([44, 1, 1])]
Shape after concatenation: torch.Size([44, 6, 1])
Shape after first reshape: torch.Size([44, 1, 6])
Shape after FC layer and dropout: torch.Size([44, 1, 1])
Shape before final padding: torch.Size([44])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5701380409021496
Prediction: True

Processing sample: TRUST_aa29778e-ccb3-490f-b8ad-aedb731b59fd_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([59, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([59, 23, 768])
Input matrix size: 1042176

Making prediction...
Original input shape: torch.Size([59, 23, 768])
Shape after padding: torch.Size([59, 24, 768])
Shape after permute: torch.Size([59, 768, 24])
Shapes after individual convolutions: [torch.Size([59, 3, 1]), torch.Size([59, 2, 1]), torch.Size([59, 1, 1])]
Shape after concatenation: torch.Size([59, 6, 1])
Shape after first reshape: torch.Size([59, 1, 6])
Shape after FC layer and dropout: torch.Size([59, 1, 1])
Shape before final padding: torch.Size([59])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6564900429930025
Prediction: True

Processing sample: TRUST_ef749f35-0531-42f1-8109-feed65aab565_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([74, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([74, 22, 768])
Input matrix size: 1250304

Making prediction...
Original input shape: torch.Size([74, 22, 768])
Shape after padding: torch.Size([74, 24, 768])
Shape after permute: torch.Size([74, 768, 24])
Shapes after individual convolutions: [torch.Size([74, 3, 1]), torch.Size([74, 2, 1]), torch.Size([74, 1, 1])]
Shape after concatenation: torch.Size([74, 6, 1])
Shape after first reshape: torch.Size([74, 1, 6])
Shape after FC layer and dropout: torch.Size([74, 1, 1])
Shape before final padding: torch.Size([74])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6615604169617932
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_29_embedding.pt
Loaded sample shape: torch.Size([100, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 20, 768])
Input matrix size: 1536000

Making prediction...
Original input shape: torch.Size([100, 20, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7023322512579088
Prediction: True

Processing sample: TRUST_c6819789-0ddf-4920-a326-2836708ce729_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([28, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([28, 21, 768])
Input matrix size: 451584

Making prediction...
Original input shape: torch.Size([28, 21, 768])
Shape after padding: torch.Size([28, 24, 768])
Shape after permute: torch.Size([28, 768, 24])
Shapes after individual convolutions: [torch.Size([28, 3, 1]), torch.Size([28, 2, 1]), torch.Size([28, 1, 1])]
Shape after concatenation: torch.Size([28, 6, 1])
Shape after first reshape: torch.Size([28, 1, 6])
Shape after FC layer and dropout: torch.Size([28, 1, 1])
Shape before final padding: torch.Size([28])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5202381471637191
Prediction: True

Processing sample: TRUST_fb8d4b28-ea5e-47cb-8465-08a475d9bfb1_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 20, 768])
Input matrix size: 1536000

Making prediction...
Original input shape: torch.Size([100, 20, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6528640612681018
Prediction: True

Processing sample: TRUST_3056b45d-df71-4b98-8b3e-01b0b78fc96c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([40, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([40, 26, 768])
Input matrix size: 798720

Making prediction...
Original input shape: torch.Size([40, 26, 768])
Shape after permute: torch.Size([40, 768, 26])
Shapes after individual convolutions: [torch.Size([40, 3, 1]), torch.Size([40, 2, 1]), torch.Size([40, 1, 1])]
Shape after concatenation: torch.Size([40, 6, 1])
Shape after first reshape: torch.Size([40, 1, 6])
Shape after FC layer and dropout: torch.Size([40, 1, 1])
Shape before final padding: torch.Size([40])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5040713617375466
Prediction: True

Processing sample: TRUST_fb40bd44-cdcf-4990-b279-a9da45383330_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([32, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([32, 21, 768])
Input matrix size: 516096

Making prediction...
Original input shape: torch.Size([32, 21, 768])
Shape after padding: torch.Size([32, 24, 768])
Shape after permute: torch.Size([32, 768, 24])
Shapes after individual convolutions: [torch.Size([32, 3, 1]), torch.Size([32, 2, 1]), torch.Size([32, 1, 1])]
Shape after concatenation: torch.Size([32, 6, 1])
Shape after first reshape: torch.Size([32, 1, 6])
Shape after FC layer and dropout: torch.Size([32, 1, 1])
Shape before final padding: torch.Size([32])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5231046894974365
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_27_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7049679525253139
Prediction: True

Processing sample: TRUST_f0cf56e0-42a4-41fd-b233-352c756eae62_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([46, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([46, 26, 768])
Input matrix size: 918528

Making prediction...
Original input shape: torch.Size([46, 26, 768])
Shape after permute: torch.Size([46, 768, 26])
Shapes after individual convolutions: [torch.Size([46, 3, 1]), torch.Size([46, 2, 1]), torch.Size([46, 1, 1])]
Shape after concatenation: torch.Size([46, 6, 1])
Shape after first reshape: torch.Size([46, 1, 6])
Shape after FC layer and dropout: torch.Size([46, 1, 1])
Shape before final padding: torch.Size([46])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.47618139927505565
Prediction: False

Processing sample: TRUST_e73048bb-abaa-44ac-b808-c2e17ba9cc46_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([47, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([47, 21, 768])
Input matrix size: 758016

Making prediction...
Original input shape: torch.Size([47, 21, 768])
Shape after padding: torch.Size([47, 24, 768])
Shape after permute: torch.Size([47, 768, 24])
Shapes after individual convolutions: [torch.Size([47, 3, 1]), torch.Size([47, 2, 1]), torch.Size([47, 1, 1])]
Shape after concatenation: torch.Size([47, 6, 1])
Shape after first reshape: torch.Size([47, 1, 6])
Shape after FC layer and dropout: torch.Size([47, 1, 1])
Shape before final padding: torch.Size([47])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5693687273499713
Prediction: True

Processing sample: TRUST_a0f80b24-6b3b-4437-a3f8-965eee631570_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([32, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([32, 20, 768])
Input matrix size: 491520

Making prediction...
Original input shape: torch.Size([32, 20, 768])
Shape after padding: torch.Size([32, 24, 768])
Shape after permute: torch.Size([32, 768, 24])
Shapes after individual convolutions: [torch.Size([32, 3, 1]), torch.Size([32, 2, 1]), torch.Size([32, 1, 1])]
Shape after concatenation: torch.Size([32, 6, 1])
Shape after first reshape: torch.Size([32, 1, 6])
Shape after FC layer and dropout: torch.Size([32, 1, 1])
Shape before final padding: torch.Size([32])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5650049088749973
Prediction: True

Processing sample: TRUST_0bdc189b-5fe6-4f58-a47b-351c2124c232_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([85, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([85, 26, 768])
Input matrix size: 1697280

Making prediction...
Original input shape: torch.Size([85, 26, 768])
Shape after permute: torch.Size([85, 768, 26])
Shapes after individual convolutions: [torch.Size([85, 3, 1]), torch.Size([85, 2, 1]), torch.Size([85, 1, 1])]
Shape after concatenation: torch.Size([85, 6, 1])
Shape after first reshape: torch.Size([85, 1, 6])
Shape after FC layer and dropout: torch.Size([85, 1, 1])
Shape before final padding: torch.Size([85])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6468110527038284
Prediction: True

Processing sample: TRUST_ca8d7caa-0fd5-4553-a38a-45faf1e138cb_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.361311112260861
Prediction: False

Processing sample: TRUST_95fd3d62-a3b3-425b-82a1-f6ec35e8734e_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([38, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([38, 20, 768])
Input matrix size: 583680

Making prediction...
Original input shape: torch.Size([38, 20, 768])
Shape after padding: torch.Size([38, 24, 768])
Shape after permute: torch.Size([38, 768, 24])
Shapes after individual convolutions: [torch.Size([38, 3, 1]), torch.Size([38, 2, 1]), torch.Size([38, 1, 1])]
Shape after concatenation: torch.Size([38, 6, 1])
Shape after first reshape: torch.Size([38, 1, 6])
Shape after FC layer and dropout: torch.Size([38, 1, 1])
Shape before final padding: torch.Size([38])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6701717511642017
Prediction: True

Processing sample: TRUST_a62c614c-9ab6-4dcc-bee1-fdc9d68df8ca_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([50, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([50, 23, 768])
Input matrix size: 883200

Making prediction...
Original input shape: torch.Size([50, 23, 768])
Shape after padding: torch.Size([50, 24, 768])
Shape after permute: torch.Size([50, 768, 24])
Shapes after individual convolutions: [torch.Size([50, 3, 1]), torch.Size([50, 2, 1]), torch.Size([50, 1, 1])]
Shape after concatenation: torch.Size([50, 6, 1])
Shape after first reshape: torch.Size([50, 1, 6])
Shape after FC layer and dropout: torch.Size([50, 1, 1])
Shape before final padding: torch.Size([50])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7024822853784083
Prediction: True

Processing sample: TRUST_5bed34fa-431e-4b3c-93a3-7e4294d006a6_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([28, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([28, 19, 768])
Input matrix size: 408576

Making prediction...
Original input shape: torch.Size([28, 19, 768])
Shape after padding: torch.Size([28, 24, 768])
Shape after permute: torch.Size([28, 768, 24])
Shapes after individual convolutions: [torch.Size([28, 3, 1]), torch.Size([28, 2, 1]), torch.Size([28, 1, 1])]
Shape after concatenation: torch.Size([28, 6, 1])
Shape after first reshape: torch.Size([28, 1, 6])
Shape after FC layer and dropout: torch.Size([28, 1, 1])
Shape before final padding: torch.Size([28])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.45181764593395524
Prediction: False

Processing sample: TRUST_8df1b7c8-38d9-4bfe-94ee-046d39c9eabf_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([36, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([36, 21, 768])
Input matrix size: 580608

Making prediction...
Original input shape: torch.Size([36, 21, 768])
Shape after padding: torch.Size([36, 24, 768])
Shape after permute: torch.Size([36, 768, 24])
Shapes after individual convolutions: [torch.Size([36, 3, 1]), torch.Size([36, 2, 1]), torch.Size([36, 1, 1])]
Shape after concatenation: torch.Size([36, 6, 1])
Shape after first reshape: torch.Size([36, 1, 6])
Shape after FC layer and dropout: torch.Size([36, 1, 1])
Shape before final padding: torch.Size([36])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5853370742088798
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_5_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6464881391768871
Prediction: True

Processing sample: TRUST_29767873-1b35-429c-a821-6d574c7678d5_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([64, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([64, 23, 768])
Input matrix size: 1130496

Making prediction...
Original input shape: torch.Size([64, 23, 768])
Shape after padding: torch.Size([64, 24, 768])
Shape after permute: torch.Size([64, 768, 24])
Shapes after individual convolutions: [torch.Size([64, 3, 1]), torch.Size([64, 2, 1]), torch.Size([64, 1, 1])]
Shape after concatenation: torch.Size([64, 6, 1])
Shape after first reshape: torch.Size([64, 1, 6])
Shape after FC layer and dropout: torch.Size([64, 1, 1])
Shape before final padding: torch.Size([64])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6715626401835054
Prediction: True

Processing sample: TRUST_0205d1df-e419-4279-861b-5bedcac06c77_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([88, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([88, 22, 768])
Input matrix size: 1486848

Making prediction...
Original input shape: torch.Size([88, 22, 768])
Shape after padding: torch.Size([88, 24, 768])
Shape after permute: torch.Size([88, 768, 24])
Shapes after individual convolutions: [torch.Size([88, 3, 1]), torch.Size([88, 2, 1]), torch.Size([88, 1, 1])]
Shape after concatenation: torch.Size([88, 6, 1])
Shape after first reshape: torch.Size([88, 1, 6])
Shape after FC layer and dropout: torch.Size([88, 1, 1])
Shape before final padding: torch.Size([88])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6295759786788041
Prediction: True

Processing sample: TRUST_b6abc578-59e6-4550-b8e6-0212f18f1a59_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([73, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([73, 22, 768])
Input matrix size: 1233408

Making prediction...
Original input shape: torch.Size([73, 22, 768])
Shape after padding: torch.Size([73, 24, 768])
Shape after permute: torch.Size([73, 768, 24])
Shapes after individual convolutions: [torch.Size([73, 3, 1]), torch.Size([73, 2, 1]), torch.Size([73, 1, 1])]
Shape after concatenation: torch.Size([73, 6, 1])
Shape after first reshape: torch.Size([73, 1, 6])
Shape after FC layer and dropout: torch.Size([73, 1, 1])
Shape before final padding: torch.Size([73])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.3358043585297321
Prediction: False

Processing sample: TRUST_65854bfb-5d68-4d10-85d5-d2e1459da8f6_airr_extracted_trb_frequencies_filtered.tsv_batch_5_embedding.pt
Loaded sample shape: torch.Size([44, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([44, 22, 768])
Input matrix size: 743424

Making prediction...
Original input shape: torch.Size([44, 22, 768])
Shape after padding: torch.Size([44, 24, 768])
Shape after permute: torch.Size([44, 768, 24])
Shapes after individual convolutions: [torch.Size([44, 3, 1]), torch.Size([44, 2, 1]), torch.Size([44, 1, 1])]
Shape after concatenation: torch.Size([44, 6, 1])
Shape after first reshape: torch.Size([44, 1, 6])
Shape after FC layer and dropout: torch.Size([44, 1, 1])
Shape before final padding: torch.Size([44])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5657102281680646
Prediction: True

Processing sample: TRUST_d64bdff8-a919-438d-bea4-8ecb01a3fc8b_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([29, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([29, 19, 768])
Input matrix size: 423168

Making prediction...
Original input shape: torch.Size([29, 19, 768])
Shape after padding: torch.Size([29, 24, 768])
Shape after permute: torch.Size([29, 768, 24])
Shapes after individual convolutions: [torch.Size([29, 3, 1]), torch.Size([29, 2, 1]), torch.Size([29, 1, 1])]
Shape after concatenation: torch.Size([29, 6, 1])
Shape after first reshape: torch.Size([29, 1, 6])
Shape after FC layer and dropout: torch.Size([29, 1, 1])
Shape before final padding: torch.Size([29])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5708046418388754
Prediction: True

Processing sample: TRUST_1e5978f1-0cb9-44fa-aaf3-b28c75a03499_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([27, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([27, 19, 768])
Input matrix size: 393984

Making prediction...
Original input shape: torch.Size([27, 19, 768])
Shape after padding: torch.Size([27, 24, 768])
Shape after permute: torch.Size([27, 768, 24])
Shapes after individual convolutions: [torch.Size([27, 3, 1]), torch.Size([27, 2, 1]), torch.Size([27, 1, 1])]
Shape after concatenation: torch.Size([27, 6, 1])
Shape after first reshape: torch.Size([27, 1, 6])
Shape after FC layer and dropout: torch.Size([27, 1, 1])
Shape before final padding: torch.Size([27])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5263645945923836
Prediction: True

Processing sample: TRUST_6b6922b0-8766-4168-9038-1c775e1f1747_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([38, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([38, 22, 768])
Input matrix size: 642048

Making prediction...
Original input shape: torch.Size([38, 22, 768])
Shape after padding: torch.Size([38, 24, 768])
Shape after permute: torch.Size([38, 768, 24])
Shapes after individual convolutions: [torch.Size([38, 3, 1]), torch.Size([38, 2, 1]), torch.Size([38, 1, 1])]
Shape after concatenation: torch.Size([38, 6, 1])
Shape after first reshape: torch.Size([38, 1, 6])
Shape after FC layer and dropout: torch.Size([38, 1, 1])
Shape before final padding: torch.Size([38])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6054926941784545
Prediction: True

Processing sample: TRUST_002079cb-bf4a-47ed-a327-fb797aa63f5c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([65, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([65, 26, 768])
Input matrix size: 1297920

Making prediction...
Original input shape: torch.Size([65, 26, 768])
Shape after permute: torch.Size([65, 768, 26])
Shapes after individual convolutions: [torch.Size([65, 3, 1]), torch.Size([65, 2, 1]), torch.Size([65, 1, 1])]
Shape after concatenation: torch.Size([65, 6, 1])
Shape after first reshape: torch.Size([65, 1, 6])
Shape after FC layer and dropout: torch.Size([65, 1, 1])
Shape before final padding: torch.Size([65])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6931450573057117
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_3_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4182700462940284
Prediction: False

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.3357606751687549
Prediction: False

Processing sample: TRUST_62d7c0c9-27eb-4cff-86f6-9c9e5ef6fd63_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([25, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([25, 21, 768])
Input matrix size: 403200

Making prediction...
Original input shape: torch.Size([25, 21, 768])
Shape after padding: torch.Size([25, 24, 768])
Shape after permute: torch.Size([25, 768, 24])
Shapes after individual convolutions: [torch.Size([25, 3, 1]), torch.Size([25, 2, 1]), torch.Size([25, 1, 1])]
Shape after concatenation: torch.Size([25, 6, 1])
Shape after first reshape: torch.Size([25, 1, 6])
Shape after FC layer and dropout: torch.Size([25, 1, 1])
Shape before final padding: torch.Size([25])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5509083345099585
Prediction: True

Processing sample: TRUST_fb4e8904-6a86-4c6e-ab3c-aa1eb174e6e4_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([66, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([66, 21, 768])
Input matrix size: 1064448

Making prediction...
Original input shape: torch.Size([66, 21, 768])
Shape after padding: torch.Size([66, 24, 768])
Shape after permute: torch.Size([66, 768, 24])
Shapes after individual convolutions: [torch.Size([66, 3, 1]), torch.Size([66, 2, 1]), torch.Size([66, 1, 1])]
Shape after concatenation: torch.Size([66, 6, 1])
Shape after first reshape: torch.Size([66, 1, 6])
Shape after FC layer and dropout: torch.Size([66, 1, 1])
Shape before final padding: torch.Size([66])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4915613350148469
Prediction: False

Processing sample: TRUST_333c75a3-b941-47a5-8c1a-760643ceceb2_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([27, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([27, 22, 768])
Input matrix size: 456192

Making prediction...
Original input shape: torch.Size([27, 22, 768])
Shape after padding: torch.Size([27, 24, 768])
Shape after permute: torch.Size([27, 768, 24])
Shapes after individual convolutions: [torch.Size([27, 3, 1]), torch.Size([27, 2, 1]), torch.Size([27, 1, 1])]
Shape after concatenation: torch.Size([27, 6, 1])
Shape after first reshape: torch.Size([27, 1, 6])
Shape after FC layer and dropout: torch.Size([27, 1, 1])
Shape before final padding: torch.Size([27])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6121530183931467
Prediction: True

Processing sample: TRUST_19d2f9a5-9e31-4bbd-965b-7bb4d3b8a53d_airr_extracted_trb_frequencies_filtered.tsv_batch_7_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7158612620766752
Prediction: True

Processing sample: TRUST_13ac52fd-ce9d-4a06-869e-a88c954ee098_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([30, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([30, 26, 768])
Input matrix size: 599040

Making prediction...
Original input shape: torch.Size([30, 26, 768])
Shape after permute: torch.Size([30, 768, 26])
Shapes after individual convolutions: [torch.Size([30, 3, 1]), torch.Size([30, 2, 1]), torch.Size([30, 1, 1])]
Shape after concatenation: torch.Size([30, 6, 1])
Shape after first reshape: torch.Size([30, 1, 6])
Shape after FC layer and dropout: torch.Size([30, 1, 1])
Shape before final padding: torch.Size([30])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5137769790342974
Prediction: True

Processing sample: TRUST_23b97dc7-3c85-445c-be9b-e6e4e02d452c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([56, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([56, 23, 768])
Input matrix size: 989184

Making prediction...
Original input shape: torch.Size([56, 23, 768])
Shape after padding: torch.Size([56, 24, 768])
Shape after permute: torch.Size([56, 768, 24])
Shapes after individual convolutions: [torch.Size([56, 3, 1]), torch.Size([56, 2, 1]), torch.Size([56, 1, 1])]
Shape after concatenation: torch.Size([56, 6, 1])
Shape after first reshape: torch.Size([56, 1, 6])
Shape after FC layer and dropout: torch.Size([56, 1, 1])
Shape before final padding: torch.Size([56])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6535514791979288
Prediction: True

Processing sample: TRUST_fcc0d141-9ca2-47c2-b1c0-4d6753e6fa20_airr_extracted_trb_frequencies_filtered.tsv_batch_7_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6424279455776895
Prediction: True

Processing sample: TRUST_81288f84-549c-4af0-8b00-c5ea0c48347f_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([84, 25, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([84, 25, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([84, 25, 768])
Shape after permute: torch.Size([84, 768, 25])
Shapes after individual convolutions: [torch.Size([84, 3, 1]), torch.Size([84, 2, 1]), torch.Size([84, 1, 1])]
Shape after concatenation: torch.Size([84, 6, 1])
Shape after first reshape: torch.Size([84, 1, 6])
Shape after FC layer and dropout: torch.Size([84, 1, 1])
Shape before final padding: torch.Size([84])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5068542686530081
Prediction: True

Processing sample: TRUST_3cf48114-c430-41e7-86a0-bfa37841a2b4_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([44, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([44, 21, 768])
Input matrix size: 709632

Making prediction...
Original input shape: torch.Size([44, 21, 768])
Shape after padding: torch.Size([44, 24, 768])
Shape after permute: torch.Size([44, 768, 24])
Shapes after individual convolutions: [torch.Size([44, 3, 1]), torch.Size([44, 2, 1]), torch.Size([44, 1, 1])]
Shape after concatenation: torch.Size([44, 6, 1])
Shape after first reshape: torch.Size([44, 1, 6])
Shape after FC layer and dropout: torch.Size([44, 1, 1])
Shape before final padding: torch.Size([44])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.509501259568822
Prediction: True

Processing sample: TRUST_51ae1076-a516-4c1f-9ba7-746b0e52423e_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([82, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([82, 26, 768])
Input matrix size: 1637376

Making prediction...
Original input shape: torch.Size([82, 26, 768])
Shape after permute: torch.Size([82, 768, 26])
Shapes after individual convolutions: [torch.Size([82, 3, 1]), torch.Size([82, 2, 1]), torch.Size([82, 1, 1])]
Shape after concatenation: torch.Size([82, 6, 1])
Shape after first reshape: torch.Size([82, 1, 6])
Shape after FC layer and dropout: torch.Size([82, 1, 1])
Shape before final padding: torch.Size([82])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5517915290410713
Prediction: True

Processing sample: TRUST_29567dfc-4b17-470c-b646-ff7ee0ad2ea2_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([96, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([96, 20, 768])
Input matrix size: 1474560

Making prediction...
Original input shape: torch.Size([96, 20, 768])
Shape after padding: torch.Size([96, 24, 768])
Shape after permute: torch.Size([96, 768, 24])
Shapes after individual convolutions: [torch.Size([96, 3, 1]), torch.Size([96, 2, 1]), torch.Size([96, 1, 1])]
Shape after concatenation: torch.Size([96, 6, 1])
Shape after first reshape: torch.Size([96, 1, 6])
Shape after FC layer and dropout: torch.Size([96, 1, 1])
Shape before final padding: torch.Size([96])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6461553071343108
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_19_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6464294937525079
Prediction: True

Processing sample: TRUST_06a354c0-ae02-499d-b9da-5b88f63d97f6_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([53, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([53, 26, 768])
Input matrix size: 1058304

Making prediction...
Original input shape: torch.Size([53, 26, 768])
Shape after permute: torch.Size([53, 768, 26])
Shapes after individual convolutions: [torch.Size([53, 3, 1]), torch.Size([53, 2, 1]), torch.Size([53, 1, 1])]
Shape after concatenation: torch.Size([53, 6, 1])
Shape after first reshape: torch.Size([53, 1, 6])
Shape after FC layer and dropout: torch.Size([53, 1, 1])
Shape before final padding: torch.Size([53])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6431630775502457
Prediction: True

Processing sample: TRUST_3b3b490d-1dd6-40b8-8847-34ff630e159d_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 19, 768])
Input matrix size: 1459200

Making prediction...
Original input shape: torch.Size([100, 19, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.668314397824093
Prediction: True

Processing sample: TRUST_19125545-fdad-411d-a389-c1820979e947_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([63, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([63, 23, 768])
Input matrix size: 1112832

Making prediction...
Original input shape: torch.Size([63, 23, 768])
Shape after padding: torch.Size([63, 24, 768])
Shape after permute: torch.Size([63, 768, 24])
Shapes after individual convolutions: [torch.Size([63, 3, 1]), torch.Size([63, 2, 1]), torch.Size([63, 1, 1])]
Shape after concatenation: torch.Size([63, 6, 1])
Shape after first reshape: torch.Size([63, 1, 6])
Shape after FC layer and dropout: torch.Size([63, 1, 1])
Shape before final padding: torch.Size([63])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6126429265957194
Prediction: True

Processing sample: TRUST_dcff17dc-7c80-41b7-885d-3207264a0c86_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([36, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([36, 22, 768])
Input matrix size: 608256

Making prediction...
Original input shape: torch.Size([36, 22, 768])
Shape after padding: torch.Size([36, 24, 768])
Shape after permute: torch.Size([36, 768, 24])
Shapes after individual convolutions: [torch.Size([36, 3, 1]), torch.Size([36, 2, 1]), torch.Size([36, 1, 1])]
Shape after concatenation: torch.Size([36, 6, 1])
Shape after first reshape: torch.Size([36, 1, 6])
Shape after FC layer and dropout: torch.Size([36, 1, 1])
Shape before final padding: torch.Size([36])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4871901669633966
Prediction: False

Processing sample: TRUST_93171b2b-61ed-44fd-a4e0-9f03ff1f1cd9_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([25, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([25, 22, 768])
Input matrix size: 422400

Making prediction...
Original input shape: torch.Size([25, 22, 768])
Shape after padding: torch.Size([25, 24, 768])
Shape after permute: torch.Size([25, 768, 24])
Shapes after individual convolutions: [torch.Size([25, 3, 1]), torch.Size([25, 2, 1]), torch.Size([25, 1, 1])]
Shape after concatenation: torch.Size([25, 6, 1])
Shape after first reshape: torch.Size([25, 1, 6])
Shape after FC layer and dropout: torch.Size([25, 1, 1])
Shape before final padding: torch.Size([25])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.3917906232091297
Prediction: False

Processing sample: TRUST_b4dc3a60-f433-4c93-acc6-a480187fc387_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([38, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([38, 22, 768])
Input matrix size: 642048

Making prediction...
Original input shape: torch.Size([38, 22, 768])
Shape after padding: torch.Size([38, 24, 768])
Shape after permute: torch.Size([38, 768, 24])
Shapes after individual convolutions: [torch.Size([38, 3, 1]), torch.Size([38, 2, 1]), torch.Size([38, 1, 1])]
Shape after concatenation: torch.Size([38, 6, 1])
Shape after first reshape: torch.Size([38, 1, 6])
Shape after FC layer and dropout: torch.Size([38, 1, 1])
Shape before final padding: torch.Size([38])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5124868485799833
Prediction: True

Processing sample: TRUST_6aac86d4-9fb5-42da-8ca8-b9c0f0022426_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([44, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([44, 26, 768])
Input matrix size: 878592

Making prediction...
Original input shape: torch.Size([44, 26, 768])
Shape after permute: torch.Size([44, 768, 26])
Shapes after individual convolutions: [torch.Size([44, 3, 1]), torch.Size([44, 2, 1]), torch.Size([44, 1, 1])]
Shape after concatenation: torch.Size([44, 6, 1])
Shape after first reshape: torch.Size([44, 1, 6])
Shape after FC layer and dropout: torch.Size([44, 1, 1])
Shape before final padding: torch.Size([44])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.45785526560953205
Prediction: False

Processing sample: TRUST_816e449f-1acc-4ff3-99c5-c1c6c8149bde_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([25, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([25, 19, 768])
Input matrix size: 364800

Making prediction...
Original input shape: torch.Size([25, 19, 768])
Shape after padding: torch.Size([25, 24, 768])
Shape after permute: torch.Size([25, 768, 24])
Shapes after individual convolutions: [torch.Size([25, 3, 1]), torch.Size([25, 2, 1]), torch.Size([25, 1, 1])]
Shape after concatenation: torch.Size([25, 6, 1])
Shape after first reshape: torch.Size([25, 1, 6])
Shape after FC layer and dropout: torch.Size([25, 1, 1])
Shape before final padding: torch.Size([25])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6064222627747439
Prediction: True

Processing sample: TRUST_f807f629-3ad0-4df7-bbf4-30fd598fd13f_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([92, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([92, 21, 768])
Input matrix size: 1483776

Making prediction...
Original input shape: torch.Size([92, 21, 768])
Shape after padding: torch.Size([92, 24, 768])
Shape after permute: torch.Size([92, 768, 24])
Shapes after individual convolutions: [torch.Size([92, 3, 1]), torch.Size([92, 2, 1]), torch.Size([92, 1, 1])]
Shape after concatenation: torch.Size([92, 6, 1])
Shape after first reshape: torch.Size([92, 1, 6])
Shape after FC layer and dropout: torch.Size([92, 1, 1])
Shape before final padding: torch.Size([92])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6679770472502752
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_24_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6604417484755568
Prediction: True

Processing sample: TRUST_f2571f49-f938-4285-ae48-3644a2a03529_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6844133059341831
Prediction: True

Processing sample: TRUST_48e3458a-198e-4013-a302-9d505b87ffdb_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([38, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([38, 23, 768])
Input matrix size: 671232

Making prediction...
Original input shape: torch.Size([38, 23, 768])
Shape after padding: torch.Size([38, 24, 768])
Shape after permute: torch.Size([38, 768, 24])
Shapes after individual convolutions: [torch.Size([38, 3, 1]), torch.Size([38, 2, 1]), torch.Size([38, 1, 1])]
Shape after concatenation: torch.Size([38, 6, 1])
Shape after first reshape: torch.Size([38, 1, 6])
Shape after FC layer and dropout: torch.Size([38, 1, 1])
Shape before final padding: torch.Size([38])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4111676388548182
Prediction: False

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_12_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7220327374362989
Prediction: True

Processing sample: TRUST_77d87cba-bcda-49e3-8f36-ca1874b2d6ee_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([29, 18, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([29, 18, 768])
Input matrix size: 400896

Making prediction...
Original input shape: torch.Size([29, 18, 768])
Shape after padding: torch.Size([29, 24, 768])
Shape after permute: torch.Size([29, 768, 24])
Shapes after individual convolutions: [torch.Size([29, 3, 1]), torch.Size([29, 2, 1]), torch.Size([29, 1, 1])]
Shape after concatenation: torch.Size([29, 6, 1])
Shape after first reshape: torch.Size([29, 1, 6])
Shape after FC layer and dropout: torch.Size([29, 1, 1])
Shape before final padding: torch.Size([29])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.49312809914538996
Prediction: False

Processing sample: TRUST_8e700b87-1876-400f-ada0-479e5257ac10_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([28, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([28, 21, 768])
Input matrix size: 451584

Making prediction...
Original input shape: torch.Size([28, 21, 768])
Shape after padding: torch.Size([28, 24, 768])
Shape after permute: torch.Size([28, 768, 24])
Shapes after individual convolutions: [torch.Size([28, 3, 1]), torch.Size([28, 2, 1]), torch.Size([28, 1, 1])]
Shape after concatenation: torch.Size([28, 6, 1])
Shape after first reshape: torch.Size([28, 1, 6])
Shape after FC layer and dropout: torch.Size([28, 1, 1])
Shape before final padding: torch.Size([28])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5950796636418376
Prediction: True

Processing sample: TRUST_eacd6dd7-93ff-47f1-bbf6-421c14e982a9_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([44, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([44, 21, 768])
Input matrix size: 709632

Making prediction...
Original input shape: torch.Size([44, 21, 768])
Shape after padding: torch.Size([44, 24, 768])
Shape after permute: torch.Size([44, 768, 24])
Shapes after individual convolutions: [torch.Size([44, 3, 1]), torch.Size([44, 2, 1]), torch.Size([44, 1, 1])]
Shape after concatenation: torch.Size([44, 6, 1])
Shape after first reshape: torch.Size([44, 1, 6])
Shape after FC layer and dropout: torch.Size([44, 1, 1])
Shape before final padding: torch.Size([44])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5492603854111547
Prediction: True

Processing sample: TRUST_19d2f9a5-9e31-4bbd-965b-7bb4d3b8a53d_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7233440613021441
Prediction: True

Processing sample: TRUST_80203ebf-5eed-4690-8ee7-b095b2d1d34c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([37, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([37, 23, 768])
Input matrix size: 653568

Making prediction...
Original input shape: torch.Size([37, 23, 768])
Shape after padding: torch.Size([37, 24, 768])
Shape after permute: torch.Size([37, 768, 24])
Shapes after individual convolutions: [torch.Size([37, 3, 1]), torch.Size([37, 2, 1]), torch.Size([37, 1, 1])]
Shape after concatenation: torch.Size([37, 6, 1])
Shape after first reshape: torch.Size([37, 1, 6])
Shape after FC layer and dropout: torch.Size([37, 1, 1])
Shape before final padding: torch.Size([37])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.3768701074452792
Prediction: False

Processing sample: TRUST_65854bfb-5d68-4d10-85d5-d2e1459da8f6_airr_extracted_trb_frequencies_filtered.tsv_batch_4_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.416037859248687
Prediction: False

Processing sample: TRUST_b934fcee-9e53-47a4-926d-952198937aa0_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([68, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([68, 21, 768])
Input matrix size: 1096704

Making prediction...
Original input shape: torch.Size([68, 21, 768])
Shape after padding: torch.Size([68, 24, 768])
Shape after permute: torch.Size([68, 768, 24])
Shapes after individual convolutions: [torch.Size([68, 3, 1]), torch.Size([68, 2, 1]), torch.Size([68, 1, 1])]
Shape after concatenation: torch.Size([68, 6, 1])
Shape after first reshape: torch.Size([68, 1, 6])
Shape after FC layer and dropout: torch.Size([68, 1, 1])
Shape before final padding: torch.Size([68])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5975063815479086
Prediction: True

Processing sample: TRUST_6aac86d4-9fb5-42da-8ca8-b9c0f0022426_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.36369917774631927
Prediction: False

Processing sample: TRUST_fcc0d141-9ca2-47c2-b1c0-4d6753e6fa20_airr_extracted_trb_frequencies_filtered.tsv_batch_5_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.364277321977122
Prediction: False

Processing sample: TRUST_2e39c90b-46ee-4168-81c5-13503cb4120d_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([55, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([55, 21, 768])
Input matrix size: 887040

Making prediction...
Original input shape: torch.Size([55, 21, 768])
Shape after padding: torch.Size([55, 24, 768])
Shape after permute: torch.Size([55, 768, 24])
Shapes after individual convolutions: [torch.Size([55, 3, 1]), torch.Size([55, 2, 1]), torch.Size([55, 1, 1])]
Shape after concatenation: torch.Size([55, 6, 1])
Shape after first reshape: torch.Size([55, 1, 6])
Shape after FC layer and dropout: torch.Size([55, 1, 1])
Shape before final padding: torch.Size([55])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.3941999099540359
Prediction: False

Processing sample: TRUST_6a4995f5-588f-4120-9b20-c1ca5bf28c39_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6624229641215701
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_17_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5749906416821121
Prediction: True

Processing sample: TRUST_cbb1fbc8-cc83-4442-be1c-4890fa570c1e_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([39, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([39, 20, 768])
Input matrix size: 599040

Making prediction...
Original input shape: torch.Size([39, 20, 768])
Shape after padding: torch.Size([39, 24, 768])
Shape after permute: torch.Size([39, 768, 24])
Shapes after individual convolutions: [torch.Size([39, 3, 1]), torch.Size([39, 2, 1]), torch.Size([39, 1, 1])]
Shape after concatenation: torch.Size([39, 6, 1])
Shape after first reshape: torch.Size([39, 1, 6])
Shape after FC layer and dropout: torch.Size([39, 1, 1])
Shape before final padding: torch.Size([39])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5623516176900312
Prediction: True

Processing sample: TRUST_a6cf6571-e320-4f1f-9bef-45cec1ba9825_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([53, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([53, 22, 768])
Input matrix size: 895488

Making prediction...
Original input shape: torch.Size([53, 22, 768])
Shape after padding: torch.Size([53, 24, 768])
Shape after permute: torch.Size([53, 768, 24])
Shapes after individual convolutions: [torch.Size([53, 3, 1]), torch.Size([53, 2, 1]), torch.Size([53, 1, 1])]
Shape after concatenation: torch.Size([53, 6, 1])
Shape after first reshape: torch.Size([53, 1, 6])
Shape after FC layer and dropout: torch.Size([53, 1, 1])
Shape before final padding: torch.Size([53])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.46004556922614187
Prediction: False

Processing sample: TRUST_d7a25385-5a4d-46b6-93f6-909f1efe3ce8_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([66, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([66, 26, 768])
Input matrix size: 1317888

Making prediction...
Original input shape: torch.Size([66, 26, 768])
Shape after permute: torch.Size([66, 768, 26])
Shapes after individual convolutions: [torch.Size([66, 3, 1]), torch.Size([66, 2, 1]), torch.Size([66, 1, 1])]
Shape after concatenation: torch.Size([66, 6, 1])
Shape after first reshape: torch.Size([66, 1, 6])
Shape after FC layer and dropout: torch.Size([66, 1, 1])
Shape before final padding: torch.Size([66])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6220151897466436
Prediction: True

Processing sample: TRUST_85c523c5-39fb-4dfb-8fda-39ab4a3827f6_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([39, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([39, 19, 768])
Input matrix size: 569088

Making prediction...
Original input shape: torch.Size([39, 19, 768])
Shape after padding: torch.Size([39, 24, 768])
Shape after permute: torch.Size([39, 768, 24])
Shapes after individual convolutions: [torch.Size([39, 3, 1]), torch.Size([39, 2, 1]), torch.Size([39, 1, 1])]
Shape after concatenation: torch.Size([39, 6, 1])
Shape after first reshape: torch.Size([39, 1, 6])
Shape after FC layer and dropout: torch.Size([39, 1, 1])
Shape before final padding: torch.Size([39])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.45021052362917885
Prediction: False

Processing sample: TRUST_25f6e426-be3f-4684-b3a3-7b9151cb207c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([74, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([74, 20, 768])
Input matrix size: 1136640

Making prediction...
Original input shape: torch.Size([74, 20, 768])
Shape after padding: torch.Size([74, 24, 768])
Shape after permute: torch.Size([74, 768, 24])
Shapes after individual convolutions: [torch.Size([74, 3, 1]), torch.Size([74, 2, 1]), torch.Size([74, 1, 1])]
Shape after concatenation: torch.Size([74, 6, 1])
Shape after first reshape: torch.Size([74, 1, 6])
Shape after FC layer and dropout: torch.Size([74, 1, 1])
Shape before final padding: torch.Size([74])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6841240434112846
Prediction: True

Processing sample: TRUST_84f66a53-029b-4727-bb2e-93c38541494f_airr_extracted_trb_frequencies_filtered.tsv_batch_3_embedding.pt
Loaded sample shape: torch.Size([78, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([78, 21, 768])
Input matrix size: 1257984

Making prediction...
Original input shape: torch.Size([78, 21, 768])
Shape after padding: torch.Size([78, 24, 768])
Shape after permute: torch.Size([78, 768, 24])
Shapes after individual convolutions: [torch.Size([78, 3, 1]), torch.Size([78, 2, 1]), torch.Size([78, 1, 1])]
Shape after concatenation: torch.Size([78, 6, 1])
Shape after first reshape: torch.Size([78, 1, 6])
Shape after FC layer and dropout: torch.Size([78, 1, 1])
Shape before final padding: torch.Size([78])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6716453412150255
Prediction: True

Processing sample: TRUST_2460175a-5c8f-4d77-89e2-6bc36204c73a_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([74, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([74, 21, 768])
Input matrix size: 1193472

Making prediction...
Original input shape: torch.Size([74, 21, 768])
Shape after padding: torch.Size([74, 24, 768])
Shape after permute: torch.Size([74, 768, 24])
Shapes after individual convolutions: [torch.Size([74, 3, 1]), torch.Size([74, 2, 1]), torch.Size([74, 1, 1])]
Shape after concatenation: torch.Size([74, 6, 1])
Shape after first reshape: torch.Size([74, 1, 6])
Shape after FC layer and dropout: torch.Size([74, 1, 1])
Shape before final padding: torch.Size([74])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.613170567656775
Prediction: True

Processing sample: TRUST_19d2f9a5-9e31-4bbd-965b-7bb4d3b8a53d_airr_extracted_trb_frequencies_filtered.tsv_batch_6_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5736450608646179
Prediction: True

Processing sample: TRUST_d8dc8330-a778-4e32-9914-9414705378e0_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([39, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([39, 26, 768])
Input matrix size: 778752

Making prediction...
Original input shape: torch.Size([39, 26, 768])
Shape after permute: torch.Size([39, 768, 26])
Shapes after individual convolutions: [torch.Size([39, 3, 1]), torch.Size([39, 2, 1]), torch.Size([39, 1, 1])]
Shape after concatenation: torch.Size([39, 6, 1])
Shape after first reshape: torch.Size([39, 1, 6])
Shape after FC layer and dropout: torch.Size([39, 1, 1])
Shape before final padding: torch.Size([39])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5669550389804477
Prediction: True

Processing sample: TRUST_157e33cd-b039-4088-a291-1e5f0033a7b2_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([28, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([28, 19, 768])
Input matrix size: 408576

Making prediction...
Original input shape: torch.Size([28, 19, 768])
Shape after padding: torch.Size([28, 24, 768])
Shape after permute: torch.Size([28, 768, 24])
Shapes after individual convolutions: [torch.Size([28, 3, 1]), torch.Size([28, 2, 1]), torch.Size([28, 1, 1])]
Shape after concatenation: torch.Size([28, 6, 1])
Shape after first reshape: torch.Size([28, 1, 6])
Shape after FC layer and dropout: torch.Size([28, 1, 1])
Shape before final padding: torch.Size([28])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.45050107193992484
Prediction: False

Processing sample: TRUST_78095b56-3a44-4654-9364-6971fc20004e_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([53, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([53, 20, 768])
Input matrix size: 814080

Making prediction...
Original input shape: torch.Size([53, 20, 768])
Shape after padding: torch.Size([53, 24, 768])
Shape after permute: torch.Size([53, 768, 24])
Shapes after individual convolutions: [torch.Size([53, 3, 1]), torch.Size([53, 2, 1]), torch.Size([53, 1, 1])]
Shape after concatenation: torch.Size([53, 6, 1])
Shape after first reshape: torch.Size([53, 1, 6])
Shape after FC layer and dropout: torch.Size([53, 1, 1])
Shape before final padding: torch.Size([53])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6453937086530314
Prediction: True

Processing sample: TRUST_89ae52ff-122a-4c93-8baa-f9264bcfaff1_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([54, 24, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([54, 24, 768])
Input matrix size: 995328

Making prediction...
Original input shape: torch.Size([54, 24, 768])
Shape after permute: torch.Size([54, 768, 24])
Shapes after individual convolutions: [torch.Size([54, 3, 1]), torch.Size([54, 2, 1]), torch.Size([54, 1, 1])]
Shape after concatenation: torch.Size([54, 6, 1])
Shape after first reshape: torch.Size([54, 1, 6])
Shape after FC layer and dropout: torch.Size([54, 1, 1])
Shape before final padding: torch.Size([54])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.35053921057640286
Prediction: False

Processing sample: TRUST_f5588194-69cc-4f74-82a6-66c69dee510a_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([26, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([26, 19, 768])
Input matrix size: 379392

Making prediction...
Original input shape: torch.Size([26, 19, 768])
Shape after padding: torch.Size([26, 24, 768])
Shape after permute: torch.Size([26, 768, 24])
Shapes after individual convolutions: [torch.Size([26, 3, 1]), torch.Size([26, 2, 1]), torch.Size([26, 1, 1])]
Shape after concatenation: torch.Size([26, 6, 1])
Shape after first reshape: torch.Size([26, 1, 6])
Shape after FC layer and dropout: torch.Size([26, 1, 1])
Shape before final padding: torch.Size([26])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5538940971210664
Prediction: True

Processing sample: TRUST_65854bfb-5d68-4d10-85d5-d2e1459da8f6_airr_extracted_trb_frequencies_filtered.tsv_batch_3_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.422047891918254
Prediction: False

Processing sample: TRUST_fe20df52-14fb-4e16-b6fc-cc8471c4c094_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([41, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([41, 20, 768])
Input matrix size: 629760

Making prediction...
Original input shape: torch.Size([41, 20, 768])
Shape after padding: torch.Size([41, 24, 768])
Shape after permute: torch.Size([41, 768, 24])
Shapes after individual convolutions: [torch.Size([41, 3, 1]), torch.Size([41, 2, 1]), torch.Size([41, 1, 1])]
Shape after concatenation: torch.Size([41, 6, 1])
Shape after first reshape: torch.Size([41, 1, 6])
Shape after FC layer and dropout: torch.Size([41, 1, 1])
Shape before final padding: torch.Size([41])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.642976521860415
Prediction: True

Processing sample: TRUST_7d2ec02f-f126-4043-b671-ea921b59e13f_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([30, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([30, 20, 768])
Input matrix size: 460800

Making prediction...
Original input shape: torch.Size([30, 20, 768])
Shape after padding: torch.Size([30, 24, 768])
Shape after permute: torch.Size([30, 768, 24])
Shapes after individual convolutions: [torch.Size([30, 3, 1]), torch.Size([30, 2, 1]), torch.Size([30, 1, 1])]
Shape after concatenation: torch.Size([30, 6, 1])
Shape after first reshape: torch.Size([30, 1, 6])
Shape after FC layer and dropout: torch.Size([30, 1, 1])
Shape before final padding: torch.Size([30])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6057105121370354
Prediction: True

Processing sample: TRUST_eb078b5e-6a60-4022-b8a5-c32f59c0649a_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([37, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([37, 19, 768])
Input matrix size: 539904

Making prediction...
Original input shape: torch.Size([37, 19, 768])
Shape after padding: torch.Size([37, 24, 768])
Shape after permute: torch.Size([37, 768, 24])
Shapes after individual convolutions: [torch.Size([37, 3, 1]), torch.Size([37, 2, 1]), torch.Size([37, 1, 1])]
Shape after concatenation: torch.Size([37, 6, 1])
Shape after first reshape: torch.Size([37, 1, 6])
Shape after FC layer and dropout: torch.Size([37, 1, 1])
Shape before final padding: torch.Size([37])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5558310361315143
Prediction: True

Processing sample: TRUST_787221c9-703b-4218-a123-dd3cc94a24c2_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([51, 24, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([51, 24, 768])
Input matrix size: 940032

Making prediction...
Original input shape: torch.Size([51, 24, 768])
Shape after permute: torch.Size([51, 768, 24])
Shapes after individual convolutions: [torch.Size([51, 3, 1]), torch.Size([51, 2, 1]), torch.Size([51, 1, 1])]
Shape after concatenation: torch.Size([51, 6, 1])
Shape after first reshape: torch.Size([51, 1, 6])
Shape after FC layer and dropout: torch.Size([51, 1, 1])
Shape before final padding: torch.Size([51])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5953363283050265
Prediction: True

Processing sample: TRUST_aac87771-4290-4664-96a6-4b0758cb35dc_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([27, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([27, 20, 768])
Input matrix size: 414720

Making prediction...
Original input shape: torch.Size([27, 20, 768])
Shape after padding: torch.Size([27, 24, 768])
Shape after permute: torch.Size([27, 768, 24])
Shapes after individual convolutions: [torch.Size([27, 3, 1]), torch.Size([27, 2, 1]), torch.Size([27, 1, 1])]
Shape after concatenation: torch.Size([27, 6, 1])
Shape after first reshape: torch.Size([27, 1, 6])
Shape after FC layer and dropout: torch.Size([27, 1, 1])
Shape before final padding: torch.Size([27])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5689826912600836
Prediction: True

Processing sample: TRUST_8128e3d0-832b-4619-b462-9a814f6397b1_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([31, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([31, 20, 768])
Input matrix size: 476160

Making prediction...
Original input shape: torch.Size([31, 20, 768])
Shape after padding: torch.Size([31, 24, 768])
Shape after permute: torch.Size([31, 768, 24])
Shapes after individual convolutions: [torch.Size([31, 3, 1]), torch.Size([31, 2, 1]), torch.Size([31, 1, 1])]
Shape after concatenation: torch.Size([31, 6, 1])
Shape after first reshape: torch.Size([31, 1, 6])
Shape after FC layer and dropout: torch.Size([31, 1, 1])
Shape before final padding: torch.Size([31])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4520455048671778
Prediction: False

Processing sample: TRUST_36a05365-f357-43d4-885b-0882c1ff33ad_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([35, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([35, 22, 768])
Input matrix size: 591360

Making prediction...
Original input shape: torch.Size([35, 22, 768])
Shape after padding: torch.Size([35, 24, 768])
Shape after permute: torch.Size([35, 768, 24])
Shapes after individual convolutions: [torch.Size([35, 3, 1]), torch.Size([35, 2, 1]), torch.Size([35, 1, 1])]
Shape after concatenation: torch.Size([35, 6, 1])
Shape after first reshape: torch.Size([35, 1, 6])
Shape after FC layer and dropout: torch.Size([35, 1, 1])
Shape before final padding: torch.Size([35])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6217843270467371
Prediction: True

Processing sample: TRUST_f1398ce0-0761-432d-9337-67faa51b6cdd_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([65, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([65, 20, 768])
Input matrix size: 998400

Making prediction...
Original input shape: torch.Size([65, 20, 768])
Shape after padding: torch.Size([65, 24, 768])
Shape after permute: torch.Size([65, 768, 24])
Shapes after individual convolutions: [torch.Size([65, 3, 1]), torch.Size([65, 2, 1]), torch.Size([65, 1, 1])]
Shape after concatenation: torch.Size([65, 6, 1])
Shape after first reshape: torch.Size([65, 1, 6])
Shape after FC layer and dropout: torch.Size([65, 1, 1])
Shape before final padding: torch.Size([65])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4491610791334599
Prediction: False

Processing sample: TRUST_f534d599-93f9-4a0e-a140-19795f173b57_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([36, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([36, 20, 768])
Input matrix size: 552960

Making prediction...
Original input shape: torch.Size([36, 20, 768])
Shape after padding: torch.Size([36, 24, 768])
Shape after permute: torch.Size([36, 768, 24])
Shapes after individual convolutions: [torch.Size([36, 3, 1]), torch.Size([36, 2, 1]), torch.Size([36, 1, 1])]
Shape after concatenation: torch.Size([36, 6, 1])
Shape after first reshape: torch.Size([36, 1, 6])
Shape after FC layer and dropout: torch.Size([36, 1, 1])
Shape before final padding: torch.Size([36])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6433078348780957
Prediction: True

Processing sample: TRUST_3b3b490d-1dd6-40b8-8847-34ff630e159d_airr_extracted_trb_frequencies_filtered.tsv_batch_8_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6987458433913069
Prediction: True

Processing sample: TRUST_670de49e-d86b-4b9e-adb3-d369156ff30f_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([21, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([21, 20, 768])
Input matrix size: 322560

Making prediction...
Original input shape: torch.Size([21, 20, 768])
Shape after padding: torch.Size([21, 24, 768])
Shape after permute: torch.Size([21, 768, 24])
Shapes after individual convolutions: [torch.Size([21, 3, 1]), torch.Size([21, 2, 1]), torch.Size([21, 1, 1])]
Shape after concatenation: torch.Size([21, 6, 1])
Shape after first reshape: torch.Size([21, 1, 6])
Shape after FC layer and dropout: torch.Size([21, 1, 1])
Shape before final padding: torch.Size([21])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5587281559169371
Prediction: True

Processing sample: TRUST_8326de55-44ae-4c87-be74-229c2b5deeeb_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([31, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([31, 20, 768])
Input matrix size: 476160

Making prediction...
Original input shape: torch.Size([31, 20, 768])
Shape after padding: torch.Size([31, 24, 768])
Shape after permute: torch.Size([31, 768, 24])
Shapes after individual convolutions: [torch.Size([31, 3, 1]), torch.Size([31, 2, 1]), torch.Size([31, 1, 1])]
Shape after concatenation: torch.Size([31, 6, 1])
Shape after first reshape: torch.Size([31, 1, 6])
Shape after FC layer and dropout: torch.Size([31, 1, 1])
Shape before final padding: torch.Size([31])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5046138422371609
Prediction: True

Processing sample: TRUST_3723f4d1-0759-488f-a61d-102cba15b29b_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([35, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([35, 19, 768])
Input matrix size: 510720

Making prediction...
Original input shape: torch.Size([35, 19, 768])
Shape after padding: torch.Size([35, 24, 768])
Shape after permute: torch.Size([35, 768, 24])
Shapes after individual convolutions: [torch.Size([35, 3, 1]), torch.Size([35, 2, 1]), torch.Size([35, 1, 1])]
Shape after concatenation: torch.Size([35, 6, 1])
Shape after first reshape: torch.Size([35, 1, 6])
Shape after FC layer and dropout: torch.Size([35, 1, 1])
Shape before final padding: torch.Size([35])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5625518673080985
Prediction: True

Processing sample: TRUST_3b3b490d-1dd6-40b8-8847-34ff630e159d_airr_extracted_trb_frequencies_filtered.tsv_batch_5_embedding.pt
Loaded sample shape: torch.Size([100, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 20, 768])
Input matrix size: 1536000

Making prediction...
Original input shape: torch.Size([100, 20, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.673131047353356
Prediction: True

Processing sample: TRUST_ab3af857-629b-4614-bb92-dcffb18a4d05_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 20, 768])
Input matrix size: 1536000

Making prediction...
Original input shape: torch.Size([100, 20, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5451700888175262
Prediction: True

Processing sample: TRUST_d0d40a66-9488-4994-a7c6-cc0bac20b066_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([25, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([25, 20, 768])
Input matrix size: 384000

Making prediction...
Original input shape: torch.Size([25, 20, 768])
Shape after padding: torch.Size([25, 24, 768])
Shape after permute: torch.Size([25, 768, 24])
Shapes after individual convolutions: [torch.Size([25, 3, 1]), torch.Size([25, 2, 1]), torch.Size([25, 1, 1])]
Shape after concatenation: torch.Size([25, 6, 1])
Shape after first reshape: torch.Size([25, 1, 6])
Shape after FC layer and dropout: torch.Size([25, 1, 1])
Shape before final padding: torch.Size([25])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.3973883279931873
Prediction: False

Processing sample: TRUST_062e2c3e-567c-4012-8d26-bcc088e15d31_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([30, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([30, 22, 768])
Input matrix size: 506880

Making prediction...
Original input shape: torch.Size([30, 22, 768])
Shape after padding: torch.Size([30, 24, 768])
Shape after permute: torch.Size([30, 768, 24])
Shapes after individual convolutions: [torch.Size([30, 3, 1]), torch.Size([30, 2, 1]), torch.Size([30, 1, 1])]
Shape after concatenation: torch.Size([30, 6, 1])
Shape after first reshape: torch.Size([30, 1, 6])
Shape after FC layer and dropout: torch.Size([30, 1, 1])
Shape before final padding: torch.Size([30])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5672993728141906
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_34_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.680309405727474
Prediction: True

Processing sample: TRUST_c898eaac-6844-4061-8165-8084adf665e5_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.40893648083845296
Prediction: False

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_25_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6390192234783292
Prediction: True

Processing sample: TRUST_3786ba73-caac-4076-9a8a-5c1607913e67_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([75, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([75, 26, 768])
Input matrix size: 1497600

Making prediction...
Original input shape: torch.Size([75, 26, 768])
Shape after permute: torch.Size([75, 768, 26])
Shapes after individual convolutions: [torch.Size([75, 3, 1]), torch.Size([75, 2, 1]), torch.Size([75, 1, 1])]
Shape after concatenation: torch.Size([75, 6, 1])
Shape after first reshape: torch.Size([75, 1, 6])
Shape after FC layer and dropout: torch.Size([75, 1, 1])
Shape before final padding: torch.Size([75])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5741097461095833
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_13_embedding.pt
Loaded sample shape: torch.Size([100, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 20, 768])
Input matrix size: 1536000

Making prediction...
Original input shape: torch.Size([100, 20, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6410620536161319
Prediction: True

Processing sample: TRUST_3b3b490d-1dd6-40b8-8847-34ff630e159d_airr_extracted_trb_frequencies_filtered.tsv_batch_9_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6660287782345681
Prediction: True

Processing sample: TRUST_ab3af857-629b-4614-bb92-dcffb18a4d05_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([9, 18, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([9, 18, 768])
Input matrix size: 124416

Making prediction...
Original input shape: torch.Size([9, 18, 768])
Shape after padding: torch.Size([9, 24, 768])
Shape after permute: torch.Size([9, 768, 24])
Shapes after individual convolutions: [torch.Size([9, 3, 1]), torch.Size([9, 2, 1]), torch.Size([9, 1, 1])]
Shape after concatenation: torch.Size([9, 6, 1])
Shape after first reshape: torch.Size([9, 1, 6])
Shape after FC layer and dropout: torch.Size([9, 1, 1])
Shape before final padding: torch.Size([9])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5179276545385789
Prediction: True

Processing sample: TRUST_2515a4ae-56ac-45bc-8fa8-2a3d3f7f9b15_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([41, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([41, 21, 768])
Input matrix size: 661248

Making prediction...
Original input shape: torch.Size([41, 21, 768])
Shape after padding: torch.Size([41, 24, 768])
Shape after permute: torch.Size([41, 768, 24])
Shapes after individual convolutions: [torch.Size([41, 3, 1]), torch.Size([41, 2, 1]), torch.Size([41, 1, 1])]
Shape after concatenation: torch.Size([41, 6, 1])
Shape after first reshape: torch.Size([41, 1, 6])
Shape after FC layer and dropout: torch.Size([41, 1, 1])
Shape before final padding: torch.Size([41])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.41517549310818513
Prediction: False

Processing sample: TRUST_e18195a1-f04d-4270-ac12-6b4e3accf8a1_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6023099610462683
Prediction: True

Processing sample: TRUST_44add336-6e3e-4074-a9f7-992dca97bbed_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([27, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([27, 20, 768])
Input matrix size: 414720

Making prediction...
Original input shape: torch.Size([27, 20, 768])
Shape after padding: torch.Size([27, 24, 768])
Shape after permute: torch.Size([27, 768, 24])
Shapes after individual convolutions: [torch.Size([27, 3, 1]), torch.Size([27, 2, 1]), torch.Size([27, 1, 1])]
Shape after concatenation: torch.Size([27, 6, 1])
Shape after first reshape: torch.Size([27, 1, 6])
Shape after FC layer and dropout: torch.Size([27, 1, 1])
Shape before final padding: torch.Size([27])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6301234738118878
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_15_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6549562085702157
Prediction: True

Processing sample: TRUST_179ffb31-e798-477c-aa05-35ae8cf82cae_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([77, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([77, 22, 768])
Input matrix size: 1300992

Making prediction...
Original input shape: torch.Size([77, 22, 768])
Shape after padding: torch.Size([77, 24, 768])
Shape after permute: torch.Size([77, 768, 24])
Shapes after individual convolutions: [torch.Size([77, 3, 1]), torch.Size([77, 2, 1]), torch.Size([77, 1, 1])]
Shape after concatenation: torch.Size([77, 6, 1])
Shape after first reshape: torch.Size([77, 1, 6])
Shape after FC layer and dropout: torch.Size([77, 1, 1])
Shape before final padding: torch.Size([77])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5784867308119603
Prediction: True

Processing sample: TRUST_c346d256-c87d-49f9-9172-cb4e58a29c3c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([27, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([27, 21, 768])
Input matrix size: 435456

Making prediction...
Original input shape: torch.Size([27, 21, 768])
Shape after padding: torch.Size([27, 24, 768])
Shape after permute: torch.Size([27, 768, 24])
Shapes after individual convolutions: [torch.Size([27, 3, 1]), torch.Size([27, 2, 1]), torch.Size([27, 1, 1])]
Shape after concatenation: torch.Size([27, 6, 1])
Shape after first reshape: torch.Size([27, 1, 6])
Shape after FC layer and dropout: torch.Size([27, 1, 1])
Shape before final padding: torch.Size([27])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5309081509141671
Prediction: True

Processing sample: TRUST_198b8772-422f-4745-9959-9c13c9bc57f2_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([51, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([51, 22, 768])
Input matrix size: 861696

Making prediction...
Original input shape: torch.Size([51, 22, 768])
Shape after padding: torch.Size([51, 24, 768])
Shape after permute: torch.Size([51, 768, 24])
Shapes after individual convolutions: [torch.Size([51, 3, 1]), torch.Size([51, 2, 1]), torch.Size([51, 1, 1])]
Shape after concatenation: torch.Size([51, 6, 1])
Shape after first reshape: torch.Size([51, 1, 6])
Shape after FC layer and dropout: torch.Size([51, 1, 1])
Shape before final padding: torch.Size([51])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5737751488537047
Prediction: True

Processing sample: TRUST_f30b60ce-703a-4608-aad6-b1673a1b016b_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 20, 768])
Input matrix size: 1536000

Making prediction...
Original input shape: torch.Size([100, 20, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6692543812680248
Prediction: True

Processing sample: TRUST_2cf68099-64eb-498d-84f2-f51ca0b80ee8_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([34, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([34, 19, 768])
Input matrix size: 496128

Making prediction...
Original input shape: torch.Size([34, 19, 768])
Shape after padding: torch.Size([34, 24, 768])
Shape after permute: torch.Size([34, 768, 24])
Shapes after individual convolutions: [torch.Size([34, 3, 1]), torch.Size([34, 2, 1]), torch.Size([34, 1, 1])]
Shape after concatenation: torch.Size([34, 6, 1])
Shape after first reshape: torch.Size([34, 1, 6])
Shape after FC layer and dropout: torch.Size([34, 1, 1])
Shape before final padding: torch.Size([34])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4328322322549251
Prediction: False

Processing sample: TRUST_d55d166c-dc41-4480-b476-0ef88acc3d32_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([32, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([32, 21, 768])
Input matrix size: 516096

Making prediction...
Original input shape: torch.Size([32, 21, 768])
Shape after padding: torch.Size([32, 24, 768])
Shape after permute: torch.Size([32, 768, 24])
Shapes after individual convolutions: [torch.Size([32, 3, 1]), torch.Size([32, 2, 1]), torch.Size([32, 1, 1])]
Shape after concatenation: torch.Size([32, 6, 1])
Shape after first reshape: torch.Size([32, 1, 6])
Shape after FC layer and dropout: torch.Size([32, 1, 1])
Shape before final padding: torch.Size([32])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4418876496988595
Prediction: False

Processing sample: TRUST_ef0e22d0-0026-4025-a942-ee234c4ee97f_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([68, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([68, 20, 768])
Input matrix size: 1044480

Making prediction...
Original input shape: torch.Size([68, 20, 768])
Shape after padding: torch.Size([68, 24, 768])
Shape after permute: torch.Size([68, 768, 24])
Shapes after individual convolutions: [torch.Size([68, 3, 1]), torch.Size([68, 2, 1]), torch.Size([68, 1, 1])]
Shape after concatenation: torch.Size([68, 6, 1])
Shape after first reshape: torch.Size([68, 1, 6])
Shape after FC layer and dropout: torch.Size([68, 1, 1])
Shape before final padding: torch.Size([68])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6362151582409407
Prediction: True

Processing sample: TRUST_b628edcd-d833-4d24-9c4d-fb4f80f041eb_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([41, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([41, 21, 768])
Input matrix size: 661248

Making prediction...
Original input shape: torch.Size([41, 21, 768])
Shape after padding: torch.Size([41, 24, 768])
Shape after permute: torch.Size([41, 768, 24])
Shapes after individual convolutions: [torch.Size([41, 3, 1]), torch.Size([41, 2, 1]), torch.Size([41, 1, 1])]
Shape after concatenation: torch.Size([41, 6, 1])
Shape after first reshape: torch.Size([41, 1, 6])
Shape after FC layer and dropout: torch.Size([41, 1, 1])
Shape before final padding: torch.Size([41])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5895603014850797
Prediction: True

Processing sample: TRUST_093d5708-05aa-4101-acd0-82d6bdcad249_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([80, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([80, 22, 768])
Input matrix size: 1351680

Making prediction...
Original input shape: torch.Size([80, 22, 768])
Shape after padding: torch.Size([80, 24, 768])
Shape after permute: torch.Size([80, 768, 24])
Shapes after individual convolutions: [torch.Size([80, 3, 1]), torch.Size([80, 2, 1]), torch.Size([80, 1, 1])]
Shape after concatenation: torch.Size([80, 6, 1])
Shape after first reshape: torch.Size([80, 1, 6])
Shape after FC layer and dropout: torch.Size([80, 1, 1])
Shape before final padding: torch.Size([80])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5895989403356134
Prediction: True

Processing sample: TRUST_435599c5-5168-4f81-9b8d-3afb38cbda1c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([40, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([40, 19, 768])
Input matrix size: 583680

Making prediction...
Original input shape: torch.Size([40, 19, 768])
Shape after padding: torch.Size([40, 24, 768])
Shape after permute: torch.Size([40, 768, 24])
Shapes after individual convolutions: [torch.Size([40, 3, 1]), torch.Size([40, 2, 1]), torch.Size([40, 1, 1])]
Shape after concatenation: torch.Size([40, 6, 1])
Shape after first reshape: torch.Size([40, 1, 6])
Shape after FC layer and dropout: torch.Size([40, 1, 1])
Shape before final padding: torch.Size([40])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5437178917651954
Prediction: True

Processing sample: TRUST_dfc0e743-2a0e-46c6-986a-f3991b8ed717_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([40, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([40, 20, 768])
Input matrix size: 614400

Making prediction...
Original input shape: torch.Size([40, 20, 768])
Shape after padding: torch.Size([40, 24, 768])
Shape after permute: torch.Size([40, 768, 24])
Shapes after individual convolutions: [torch.Size([40, 3, 1]), torch.Size([40, 2, 1]), torch.Size([40, 1, 1])]
Shape after concatenation: torch.Size([40, 6, 1])
Shape after first reshape: torch.Size([40, 1, 6])
Shape after FC layer and dropout: torch.Size([40, 1, 1])
Shape before final padding: torch.Size([40])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.518177831396364
Prediction: True

Processing sample: TRUST_858a7774-a964-41ea-99df-b211b011e6fc_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5938357957415588
Prediction: True

Processing sample: TRUST_fcf29edc-a464-42f8-8ed4-ac56d5c39bbf_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6739108965443518
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_21_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5534735364261449
Prediction: True

Processing sample: TRUST_670de49e-d86b-4b9e-adb3-d369156ff30f_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 23, 768])
Input matrix size: 1766400

Making prediction...
Original input shape: torch.Size([100, 23, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6735401812449645
Prediction: True

Processing sample: TRUST_e2704437-4858-41c0-b9aa-889c6ebf1c21_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([67, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([67, 20, 768])
Input matrix size: 1029120

Making prediction...
Original input shape: torch.Size([67, 20, 768])
Shape after padding: torch.Size([67, 24, 768])
Shape after permute: torch.Size([67, 768, 24])
Shapes after individual convolutions: [torch.Size([67, 3, 1]), torch.Size([67, 2, 1]), torch.Size([67, 1, 1])]
Shape after concatenation: torch.Size([67, 6, 1])
Shape after first reshape: torch.Size([67, 1, 6])
Shape after FC layer and dropout: torch.Size([67, 1, 1])
Shape before final padding: torch.Size([67])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.623670965989105
Prediction: True

Processing sample: TRUST_93c435ca-6416-46eb-9f5d-921da8fb155c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([68, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([68, 22, 768])
Input matrix size: 1148928

Making prediction...
Original input shape: torch.Size([68, 22, 768])
Shape after padding: torch.Size([68, 24, 768])
Shape after permute: torch.Size([68, 768, 24])
Shapes after individual convolutions: [torch.Size([68, 3, 1]), torch.Size([68, 2, 1]), torch.Size([68, 1, 1])]
Shape after concatenation: torch.Size([68, 6, 1])
Shape after first reshape: torch.Size([68, 1, 6])
Shape after FC layer and dropout: torch.Size([68, 1, 1])
Shape before final padding: torch.Size([68])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6420270390197488
Prediction: True

Processing sample: TRUST_a56af499-d952-4f41-802c-b61e83c7ec66_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([30, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([30, 20, 768])
Input matrix size: 460800

Making prediction...
Original input shape: torch.Size([30, 20, 768])
Shape after padding: torch.Size([30, 24, 768])
Shape after permute: torch.Size([30, 768, 24])
Shapes after individual convolutions: [torch.Size([30, 3, 1]), torch.Size([30, 2, 1]), torch.Size([30, 1, 1])]
Shape after concatenation: torch.Size([30, 6, 1])
Shape after first reshape: torch.Size([30, 1, 6])
Shape after FC layer and dropout: torch.Size([30, 1, 1])
Shape before final padding: torch.Size([30])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5052962408384961
Prediction: True

Processing sample: TRUST_2c4c484d-12b2-4791-aa26-754f7d16d643_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([58, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([58, 19, 768])
Input matrix size: 846336

Making prediction...
Original input shape: torch.Size([58, 19, 768])
Shape after padding: torch.Size([58, 24, 768])
Shape after permute: torch.Size([58, 768, 24])
Shapes after individual convolutions: [torch.Size([58, 3, 1]), torch.Size([58, 2, 1]), torch.Size([58, 1, 1])]
Shape after concatenation: torch.Size([58, 6, 1])
Shape after first reshape: torch.Size([58, 1, 6])
Shape after FC layer and dropout: torch.Size([58, 1, 1])
Shape before final padding: torch.Size([58])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5522421346901458
Prediction: True

Processing sample: TRUST_e28fa0f9-db56-4c16-a6d6-15f8751e11cd_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 23, 768])
Input matrix size: 1766400

Making prediction...
Original input shape: torch.Size([100, 23, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6878307976625024
Prediction: True

Processing sample: TRUST_19d2f9a5-9e31-4bbd-965b-7bb4d3b8a53d_airr_extracted_trb_frequencies_filtered.tsv_batch_4_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6123685369584482
Prediction: True

Processing sample: TRUST_fcc0d141-9ca2-47c2-b1c0-4d6753e6fa20_airr_extracted_trb_frequencies_filtered.tsv_batch_6_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6490294093810494
Prediction: True

Processing sample: TRUST_e6d4f9e4-e997-405e-aefa-3ec75d52e051_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([29, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([29, 21, 768])
Input matrix size: 467712

Making prediction...
Original input shape: torch.Size([29, 21, 768])
Shape after padding: torch.Size([29, 24, 768])
Shape after permute: torch.Size([29, 768, 24])
Shapes after individual convolutions: [torch.Size([29, 3, 1]), torch.Size([29, 2, 1]), torch.Size([29, 1, 1])]
Shape after concatenation: torch.Size([29, 6, 1])
Shape after first reshape: torch.Size([29, 1, 6])
Shape after FC layer and dropout: torch.Size([29, 1, 1])
Shape before final padding: torch.Size([29])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.43595994808197275
Prediction: False

Processing sample: TRUST_e38736db-29f5-4e7c-af97-4c6a23607a3b_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([41, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([41, 21, 768])
Input matrix size: 661248

Making prediction...
Original input shape: torch.Size([41, 21, 768])
Shape after padding: torch.Size([41, 24, 768])
Shape after permute: torch.Size([41, 768, 24])
Shapes after individual convolutions: [torch.Size([41, 3, 1]), torch.Size([41, 2, 1]), torch.Size([41, 1, 1])]
Shape after concatenation: torch.Size([41, 6, 1])
Shape after first reshape: torch.Size([41, 1, 6])
Shape after FC layer and dropout: torch.Size([41, 1, 1])
Shape before final padding: torch.Size([41])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5209785328024472
Prediction: True

Processing sample: TRUST_558c9326-02f3-483b-853f-f5033625d96c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([28, 18, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([28, 18, 768])
Input matrix size: 387072

Making prediction...
Original input shape: torch.Size([28, 18, 768])
Shape after padding: torch.Size([28, 24, 768])
Shape after permute: torch.Size([28, 768, 24])
Shapes after individual convolutions: [torch.Size([28, 3, 1]), torch.Size([28, 2, 1]), torch.Size([28, 1, 1])]
Shape after concatenation: torch.Size([28, 6, 1])
Shape after first reshape: torch.Size([28, 1, 6])
Shape after FC layer and dropout: torch.Size([28, 1, 1])
Shape before final padding: torch.Size([28])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4365348555868291
Prediction: False

Processing sample: TRUST_a7837557-acf7-47a2-9dbe-64d7df9ef37f_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([57, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([57, 19, 768])
Input matrix size: 831744

Making prediction...
Original input shape: torch.Size([57, 19, 768])
Shape after padding: torch.Size([57, 24, 768])
Shape after permute: torch.Size([57, 768, 24])
Shapes after individual convolutions: [torch.Size([57, 3, 1]), torch.Size([57, 2, 1]), torch.Size([57, 1, 1])]
Shape after concatenation: torch.Size([57, 6, 1])
Shape after first reshape: torch.Size([57, 1, 6])
Shape after FC layer and dropout: torch.Size([57, 1, 1])
Shape before final padding: torch.Size([57])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5657307074076998
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_30_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6533069892745799
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_4_embedding.pt
Loaded sample shape: torch.Size([100, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 23, 768])
Input matrix size: 1766400

Making prediction...
Original input shape: torch.Size([100, 23, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7073993836416098
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_11_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5337331353075889
Prediction: True

Processing sample: TRUST_c1d53d79-ec0b-4c77-be68-8b34eaa014f0_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([95, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([95, 22, 768])
Input matrix size: 1605120

Making prediction...
Original input shape: torch.Size([95, 22, 768])
Shape after padding: torch.Size([95, 24, 768])
Shape after permute: torch.Size([95, 768, 24])
Shapes after individual convolutions: [torch.Size([95, 3, 1]), torch.Size([95, 2, 1]), torch.Size([95, 1, 1])]
Shape after concatenation: torch.Size([95, 6, 1])
Shape after first reshape: torch.Size([95, 1, 6])
Shape after FC layer and dropout: torch.Size([95, 1, 1])
Shape before final padding: torch.Size([95])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6782555723223793
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_23_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6463595494056219
Prediction: True

Processing sample: TRUST_aa97a4a2-0044-4598-91a8-c8794ed28d11_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([25, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([25, 19, 768])
Input matrix size: 364800

Making prediction...
Original input shape: torch.Size([25, 19, 768])
Shape after padding: torch.Size([25, 24, 768])
Shape after permute: torch.Size([25, 768, 24])
Shapes after individual convolutions: [torch.Size([25, 3, 1]), torch.Size([25, 2, 1]), torch.Size([25, 1, 1])]
Shape after concatenation: torch.Size([25, 6, 1])
Shape after first reshape: torch.Size([25, 1, 6])
Shape after FC layer and dropout: torch.Size([25, 1, 1])
Shape before final padding: torch.Size([25])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6134316809161388
Prediction: True

Processing sample: TRUST_46c68cdd-6b3e-495b-aa87-4dfbf2d174c4_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([26, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([26, 21, 768])
Input matrix size: 419328

Making prediction...
Original input shape: torch.Size([26, 21, 768])
Shape after padding: torch.Size([26, 24, 768])
Shape after permute: torch.Size([26, 768, 24])
Shapes after individual convolutions: [torch.Size([26, 3, 1]), torch.Size([26, 2, 1]), torch.Size([26, 1, 1])]
Shape after concatenation: torch.Size([26, 6, 1])
Shape after first reshape: torch.Size([26, 1, 6])
Shape after FC layer and dropout: torch.Size([26, 1, 1])
Shape before final padding: torch.Size([26])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5593969772714242
Prediction: True

Processing sample: TRUST_cb087a32-5b01-480e-8e6a-1a77a871133f_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([30, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([30, 20, 768])
Input matrix size: 460800

Making prediction...
Original input shape: torch.Size([30, 20, 768])
Shape after padding: torch.Size([30, 24, 768])
Shape after permute: torch.Size([30, 768, 24])
Shapes after individual convolutions: [torch.Size([30, 3, 1]), torch.Size([30, 2, 1]), torch.Size([30, 1, 1])]
Shape after concatenation: torch.Size([30, 6, 1])
Shape after first reshape: torch.Size([30, 1, 6])
Shape after FC layer and dropout: torch.Size([30, 1, 1])
Shape before final padding: torch.Size([30])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5266635925989399
Prediction: True

Processing sample: TRUST_38dd29ce-7af4-4958-81d0-d993d2a22433_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([97, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([97, 20, 768])
Input matrix size: 1489920

Making prediction...
Original input shape: torch.Size([97, 20, 768])
Shape after padding: torch.Size([97, 24, 768])
Shape after permute: torch.Size([97, 768, 24])
Shapes after individual convolutions: [torch.Size([97, 3, 1]), torch.Size([97, 2, 1]), torch.Size([97, 1, 1])]
Shape after concatenation: torch.Size([97, 6, 1])
Shape after first reshape: torch.Size([97, 1, 6])
Shape after FC layer and dropout: torch.Size([97, 1, 1])
Shape before final padding: torch.Size([97])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5883819445715254
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_28_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.704698393704282
Prediction: True

Processing sample: TRUST_84f66a53-029b-4727-bb2e-93c38541494f_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7014105225614341
Prediction: True

Processing sample: TRUST_020ed736-5e9c-4f64-af48-fc5c281ce687_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([85, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([85, 23, 768])
Input matrix size: 1501440

Making prediction...
Original input shape: torch.Size([85, 23, 768])
Shape after padding: torch.Size([85, 24, 768])
Shape after permute: torch.Size([85, 768, 24])
Shapes after individual convolutions: [torch.Size([85, 3, 1]), torch.Size([85, 2, 1]), torch.Size([85, 1, 1])]
Shape after concatenation: torch.Size([85, 6, 1])
Shape after first reshape: torch.Size([85, 1, 6])
Shape after FC layer and dropout: torch.Size([85, 1, 1])
Shape before final padding: torch.Size([85])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6782947878364012
Prediction: True

Processing sample: TRUST_cf3da1d9-dbbe-49f1-b309-8befa341b49c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([64, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([64, 20, 768])
Input matrix size: 983040

Making prediction...
Original input shape: torch.Size([64, 20, 768])
Shape after padding: torch.Size([64, 24, 768])
Shape after permute: torch.Size([64, 768, 24])
Shapes after individual convolutions: [torch.Size([64, 3, 1]), torch.Size([64, 2, 1]), torch.Size([64, 1, 1])]
Shape after concatenation: torch.Size([64, 6, 1])
Shape after first reshape: torch.Size([64, 1, 6])
Shape after FC layer and dropout: torch.Size([64, 1, 1])
Shape before final padding: torch.Size([64])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6184678964069504
Prediction: True

Processing sample: TRUST_8013c0d9-ef09-4c62-ad8f-d563db506cb6_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([31, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([31, 19, 768])
Input matrix size: 452352

Making prediction...
Original input shape: torch.Size([31, 19, 768])
Shape after padding: torch.Size([31, 24, 768])
Shape after permute: torch.Size([31, 768, 24])
Shapes after individual convolutions: [torch.Size([31, 3, 1]), torch.Size([31, 2, 1]), torch.Size([31, 1, 1])]
Shape after concatenation: torch.Size([31, 6, 1])
Shape after first reshape: torch.Size([31, 1, 6])
Shape after FC layer and dropout: torch.Size([31, 1, 1])
Shape before final padding: torch.Size([31])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5643815156235197
Prediction: True

Processing sample: TRUST_b6985e24-bcf0-4da4-9887-6f5092c3537d_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([81, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([81, 26, 768])
Input matrix size: 1617408

Making prediction...
Original input shape: torch.Size([81, 26, 768])
Shape after permute: torch.Size([81, 768, 26])
Shapes after individual convolutions: [torch.Size([81, 3, 1]), torch.Size([81, 2, 1]), torch.Size([81, 1, 1])]
Shape after concatenation: torch.Size([81, 6, 1])
Shape after first reshape: torch.Size([81, 1, 6])
Shape after FC layer and dropout: torch.Size([81, 1, 1])
Shape before final padding: torch.Size([81])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6897490693795887
Prediction: True

Processing sample: TRUST_a8fa3adb-f405-448b-abad-3b971fe19286_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([29, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([29, 20, 768])
Input matrix size: 445440

Making prediction...
Original input shape: torch.Size([29, 20, 768])
Shape after padding: torch.Size([29, 24, 768])
Shape after permute: torch.Size([29, 768, 24])
Shapes after individual convolutions: [torch.Size([29, 3, 1]), torch.Size([29, 2, 1]), torch.Size([29, 1, 1])]
Shape after concatenation: torch.Size([29, 6, 1])
Shape after first reshape: torch.Size([29, 1, 6])
Shape after FC layer and dropout: torch.Size([29, 1, 1])
Shape before final padding: torch.Size([29])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5593090652082047
Prediction: True

Processing sample: TRUST_2016ed68-bccd-4995-85c9-0e7611028811_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([93, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([93, 22, 768])
Input matrix size: 1571328

Making prediction...
Original input shape: torch.Size([93, 22, 768])
Shape after padding: torch.Size([93, 24, 768])
Shape after permute: torch.Size([93, 768, 24])
Shapes after individual convolutions: [torch.Size([93, 3, 1]), torch.Size([93, 2, 1]), torch.Size([93, 1, 1])]
Shape after concatenation: torch.Size([93, 6, 1])
Shape after first reshape: torch.Size([93, 1, 6])
Shape after FC layer and dropout: torch.Size([93, 1, 1])
Shape before final padding: torch.Size([93])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6767305094860667
Prediction: True

Processing sample: TRUST_d112b2e2-54dd-4ce0-be4c-2b5740ec4e40_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([29, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([29, 20, 768])
Input matrix size: 445440

Making prediction...
Original input shape: torch.Size([29, 20, 768])
Shape after padding: torch.Size([29, 24, 768])
Shape after permute: torch.Size([29, 768, 24])
Shapes after individual convolutions: [torch.Size([29, 3, 1]), torch.Size([29, 2, 1]), torch.Size([29, 1, 1])]
Shape after concatenation: torch.Size([29, 6, 1])
Shape after first reshape: torch.Size([29, 1, 6])
Shape after FC layer and dropout: torch.Size([29, 1, 1])
Shape before final padding: torch.Size([29])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6371485667047943
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_7_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6050487355449273
Prediction: True

Processing sample: TRUST_19d2f9a5-9e31-4bbd-965b-7bb4d3b8a53d_airr_extracted_trb_frequencies_filtered.tsv_batch_11_embedding.pt
Loaded sample shape: torch.Size([68, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([68, 21, 768])
Input matrix size: 1096704

Making prediction...
Original input shape: torch.Size([68, 21, 768])
Shape after padding: torch.Size([68, 24, 768])
Shape after permute: torch.Size([68, 768, 24])
Shapes after individual convolutions: [torch.Size([68, 3, 1]), torch.Size([68, 2, 1]), torch.Size([68, 1, 1])]
Shape after concatenation: torch.Size([68, 6, 1])
Shape after first reshape: torch.Size([68, 1, 6])
Shape after FC layer and dropout: torch.Size([68, 1, 1])
Shape before final padding: torch.Size([68])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6915024151079278
Prediction: True

Processing sample: TRUST_fd5fa21b-bdbe-4326-bee6-a15daaefdb51_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([59, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([59, 22, 768])
Input matrix size: 996864

Making prediction...
Original input shape: torch.Size([59, 22, 768])
Shape after padding: torch.Size([59, 24, 768])
Shape after permute: torch.Size([59, 768, 24])
Shapes after individual convolutions: [torch.Size([59, 3, 1]), torch.Size([59, 2, 1]), torch.Size([59, 1, 1])]
Shape after concatenation: torch.Size([59, 6, 1])
Shape after first reshape: torch.Size([59, 1, 6])
Shape after FC layer and dropout: torch.Size([59, 1, 1])
Shape before final padding: torch.Size([59])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6397805114588443
Prediction: True

Processing sample: TRUST_f55f7211-40bb-402a-9319-ea9089e96f93_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([30, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([30, 19, 768])
Input matrix size: 437760

Making prediction...
Original input shape: torch.Size([30, 19, 768])
Shape after padding: torch.Size([30, 24, 768])
Shape after permute: torch.Size([30, 768, 24])
Shapes after individual convolutions: [torch.Size([30, 3, 1]), torch.Size([30, 2, 1]), torch.Size([30, 1, 1])]
Shape after concatenation: torch.Size([30, 6, 1])
Shape after first reshape: torch.Size([30, 1, 6])
Shape after FC layer and dropout: torch.Size([30, 1, 1])
Shape before final padding: torch.Size([30])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.47224434912642466
Prediction: False

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_32_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5689922218613765
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_22_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6824247616123168
Prediction: True

Processing sample: TRUST_6a994be9-cdcb-41fc-8511-c875f317f874_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([52, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([52, 20, 768])
Input matrix size: 798720

Making prediction...
Original input shape: torch.Size([52, 20, 768])
Shape after padding: torch.Size([52, 24, 768])
Shape after permute: torch.Size([52, 768, 24])
Shapes after individual convolutions: [torch.Size([52, 3, 1]), torch.Size([52, 2, 1]), torch.Size([52, 1, 1])]
Shape after concatenation: torch.Size([52, 6, 1])
Shape after first reshape: torch.Size([52, 1, 6])
Shape after FC layer and dropout: torch.Size([52, 1, 1])
Shape before final padding: torch.Size([52])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5396897768941777
Prediction: True

Processing sample: TRUST_389a8b08-20b5-448f-b6a6-f6949a34c814_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([30, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([30, 19, 768])
Input matrix size: 437760

Making prediction...
Original input shape: torch.Size([30, 19, 768])
Shape after padding: torch.Size([30, 24, 768])
Shape after permute: torch.Size([30, 768, 24])
Shapes after individual convolutions: [torch.Size([30, 3, 1]), torch.Size([30, 2, 1]), torch.Size([30, 1, 1])]
Shape after concatenation: torch.Size([30, 6, 1])
Shape after first reshape: torch.Size([30, 1, 6])
Shape after FC layer and dropout: torch.Size([30, 1, 1])
Shape before final padding: torch.Size([30])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6376958135663741
Prediction: True

Processing sample: TRUST_e5e769c1-eed2-4600-8adc-d06be86b8ee5_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([31, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([31, 19, 768])
Input matrix size: 452352

Making prediction...
Original input shape: torch.Size([31, 19, 768])
Shape after padding: torch.Size([31, 24, 768])
Shape after permute: torch.Size([31, 768, 24])
Shapes after individual convolutions: [torch.Size([31, 3, 1]), torch.Size([31, 2, 1]), torch.Size([31, 1, 1])]
Shape after concatenation: torch.Size([31, 6, 1])
Shape after first reshape: torch.Size([31, 1, 6])
Shape after FC layer and dropout: torch.Size([31, 1, 1])
Shape before final padding: torch.Size([31])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5662796677733821
Prediction: True

Processing sample: TRUST_a23ef756-9472-4f9f-b9bb-6c2c1bf25b53_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([28, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([28, 20, 768])
Input matrix size: 430080

Making prediction...
Original input shape: torch.Size([28, 20, 768])
Shape after padding: torch.Size([28, 24, 768])
Shape after permute: torch.Size([28, 768, 24])
Shapes after individual convolutions: [torch.Size([28, 3, 1]), torch.Size([28, 2, 1]), torch.Size([28, 1, 1])]
Shape after concatenation: torch.Size([28, 6, 1])
Shape after first reshape: torch.Size([28, 1, 6])
Shape after FC layer and dropout: torch.Size([28, 1, 1])
Shape before final padding: torch.Size([28])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6406028658282714
Prediction: True

Processing sample: TRUST_dd47e7e2-2298-4720-becd-805258ce14dd_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([80, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([80, 20, 768])
Input matrix size: 1228800

Making prediction...
Original input shape: torch.Size([80, 20, 768])
Shape after padding: torch.Size([80, 24, 768])
Shape after permute: torch.Size([80, 768, 24])
Shapes after individual convolutions: [torch.Size([80, 3, 1]), torch.Size([80, 2, 1]), torch.Size([80, 1, 1])]
Shape after concatenation: torch.Size([80, 6, 1])
Shape after first reshape: torch.Size([80, 1, 6])
Shape after FC layer and dropout: torch.Size([80, 1, 1])
Shape before final padding: torch.Size([80])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5949651404569328
Prediction: True

Processing sample: TRUST_ea5a08d3-eb70-4be3-a587-f3721401400c_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([33, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([33, 23, 768])
Input matrix size: 582912

Making prediction...
Original input shape: torch.Size([33, 23, 768])
Shape after padding: torch.Size([33, 24, 768])
Shape after permute: torch.Size([33, 768, 24])
Shapes after individual convolutions: [torch.Size([33, 3, 1]), torch.Size([33, 2, 1]), torch.Size([33, 1, 1])]
Shape after concatenation: torch.Size([33, 6, 1])
Shape after first reshape: torch.Size([33, 1, 6])
Shape after FC layer and dropout: torch.Size([33, 1, 1])
Shape before final padding: torch.Size([33])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5694914908669889
Prediction: True

Processing sample: TRUST_e31cc60d-6b26-4686-a27c-3cbb8a5bd1f6_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([85, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([85, 22, 768])
Input matrix size: 1436160

Making prediction...
Original input shape: torch.Size([85, 22, 768])
Shape after padding: torch.Size([85, 24, 768])
Shape after permute: torch.Size([85, 768, 24])
Shapes after individual convolutions: [torch.Size([85, 3, 1]), torch.Size([85, 2, 1]), torch.Size([85, 1, 1])]
Shape after concatenation: torch.Size([85, 6, 1])
Shape after first reshape: torch.Size([85, 1, 6])
Shape after FC layer and dropout: torch.Size([85, 1, 1])
Shape before final padding: torch.Size([85])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7040082837323071
Prediction: True

Processing sample: TRUST_f666680e-ec6d-49bc-9a26-34737814eeb9_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([25, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([25, 21, 768])
Input matrix size: 403200

Making prediction...
Original input shape: torch.Size([25, 21, 768])
Shape after padding: torch.Size([25, 24, 768])
Shape after permute: torch.Size([25, 768, 24])
Shapes after individual convolutions: [torch.Size([25, 3, 1]), torch.Size([25, 2, 1]), torch.Size([25, 1, 1])]
Shape after concatenation: torch.Size([25, 6, 1])
Shape after first reshape: torch.Size([25, 1, 6])
Shape after FC layer and dropout: torch.Size([25, 1, 1])
Shape before final padding: torch.Size([25])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6311758476096533
Prediction: True

Processing sample: TRUST_e424ca9f-cf37-4a3c-b1c9-623e3456c96d_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([36, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([36, 21, 768])
Input matrix size: 580608

Making prediction...
Original input shape: torch.Size([36, 21, 768])
Shape after padding: torch.Size([36, 24, 768])
Shape after permute: torch.Size([36, 768, 24])
Shapes after individual convolutions: [torch.Size([36, 3, 1]), torch.Size([36, 2, 1]), torch.Size([36, 1, 1])]
Shape after concatenation: torch.Size([36, 6, 1])
Shape after first reshape: torch.Size([36, 1, 6])
Shape after FC layer and dropout: torch.Size([36, 1, 1])
Shape before final padding: torch.Size([36])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5106884495860129
Prediction: True

Processing sample: TRUST_f247c909-3278-4b1e-983f-833276dc8be0_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6895790563681768
Prediction: True

Processing sample: TRUST_eb5a1b23-4c4b-4a6f-b5cb-1b72cc38c56a_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([75, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([75, 23, 768])
Input matrix size: 1324800

Making prediction...
Original input shape: torch.Size([75, 23, 768])
Shape after padding: torch.Size([75, 24, 768])
Shape after permute: torch.Size([75, 768, 24])
Shapes after individual convolutions: [torch.Size([75, 3, 1]), torch.Size([75, 2, 1]), torch.Size([75, 1, 1])]
Shape after concatenation: torch.Size([75, 6, 1])
Shape after first reshape: torch.Size([75, 1, 6])
Shape after FC layer and dropout: torch.Size([75, 1, 1])
Shape before final padding: torch.Size([75])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5624242227213729
Prediction: True

Processing sample: TRUST_c1a91a6e-6dff-4546-a469-cc56ed09bab2_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([39, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([39, 21, 768])
Input matrix size: 628992

Making prediction...
Original input shape: torch.Size([39, 21, 768])
Shape after padding: torch.Size([39, 24, 768])
Shape after permute: torch.Size([39, 768, 24])
Shapes after individual convolutions: [torch.Size([39, 3, 1]), torch.Size([39, 2, 1]), torch.Size([39, 1, 1])]
Shape after concatenation: torch.Size([39, 6, 1])
Shape after first reshape: torch.Size([39, 1, 6])
Shape after FC layer and dropout: torch.Size([39, 1, 1])
Shape before final padding: torch.Size([39])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6432962503307958
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_16_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6871975595491452
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_9_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6565901617319341
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.700596292168682
Prediction: True

Processing sample: TRUST_f9540ce1-1a0f-4d93-a5da-1fff9d78b01d_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([49, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([49, 21, 768])
Input matrix size: 790272

Making prediction...
Original input shape: torch.Size([49, 21, 768])
Shape after padding: torch.Size([49, 24, 768])
Shape after permute: torch.Size([49, 768, 24])
Shapes after individual convolutions: [torch.Size([49, 3, 1]), torch.Size([49, 2, 1]), torch.Size([49, 1, 1])]
Shape after concatenation: torch.Size([49, 6, 1])
Shape after first reshape: torch.Size([49, 1, 6])
Shape after FC layer and dropout: torch.Size([49, 1, 1])
Shape before final padding: torch.Size([49])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5206849391117786
Prediction: True

Processing sample: TRUST_fcf29edc-a464-42f8-8ed4-ac56d5c39bbf_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.611263319896448
Prediction: True

Processing sample: TRUST_a2cb741c-d2c3-45a7-8d97-9a2f2243d476_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([29, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([29, 26, 768])
Input matrix size: 579072

Making prediction...
Original input shape: torch.Size([29, 26, 768])
Shape after permute: torch.Size([29, 768, 26])
Shapes after individual convolutions: [torch.Size([29, 3, 1]), torch.Size([29, 2, 1]), torch.Size([29, 1, 1])]
Shape after concatenation: torch.Size([29, 6, 1])
Shape after first reshape: torch.Size([29, 1, 6])
Shape after FC layer and dropout: torch.Size([29, 1, 1])
Shape before final padding: torch.Size([29])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5924749703535047
Prediction: True

Processing sample: TRUST_1b929291-17f2-4818-84f9-b10d865aa541_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([70, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([70, 20, 768])
Input matrix size: 1075200

Making prediction...
Original input shape: torch.Size([70, 20, 768])
Shape after padding: torch.Size([70, 24, 768])
Shape after permute: torch.Size([70, 768, 24])
Shapes after individual convolutions: [torch.Size([70, 3, 1]), torch.Size([70, 2, 1]), torch.Size([70, 1, 1])]
Shape after concatenation: torch.Size([70, 6, 1])
Shape after first reshape: torch.Size([70, 1, 6])
Shape after FC layer and dropout: torch.Size([70, 1, 1])
Shape before final padding: torch.Size([70])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6305248326990536
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_8_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.710290141821789
Prediction: True

Processing sample: TRUST_fcc0d141-9ca2-47c2-b1c0-4d6753e6fa20_airr_extracted_trb_frequencies_filtered.tsv_batch_3_embedding.pt
Loaded sample shape: torch.Size([100, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 23, 768])
Input matrix size: 1766400

Making prediction...
Original input shape: torch.Size([100, 23, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6353524510371766
Prediction: True

Processing sample: TRUST_aee34e47-1eb2-4f58-82e8-201f38efec1f_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([43, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([43, 23, 768])
Input matrix size: 759552

Making prediction...
Original input shape: torch.Size([43, 23, 768])
Shape after padding: torch.Size([43, 24, 768])
Shape after permute: torch.Size([43, 768, 24])
Shapes after individual convolutions: [torch.Size([43, 3, 1]), torch.Size([43, 2, 1]), torch.Size([43, 1, 1])]
Shape after concatenation: torch.Size([43, 6, 1])
Shape after first reshape: torch.Size([43, 1, 6])
Shape after FC layer and dropout: torch.Size([43, 1, 1])
Shape before final padding: torch.Size([43])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6161877578268248
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_6_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4563495092820216
Prediction: False

Processing sample: TRUST_cd3b9637-ee7d-45a4-b8a1-4eb10a230344_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([45, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([45, 23, 768])
Input matrix size: 794880

Making prediction...
Original input shape: torch.Size([45, 23, 768])
Shape after padding: torch.Size([45, 24, 768])
Shape after permute: torch.Size([45, 768, 24])
Shapes after individual convolutions: [torch.Size([45, 3, 1]), torch.Size([45, 2, 1]), torch.Size([45, 1, 1])]
Shape after concatenation: torch.Size([45, 6, 1])
Shape after first reshape: torch.Size([45, 1, 6])
Shape after FC layer and dropout: torch.Size([45, 1, 1])
Shape before final padding: torch.Size([45])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5483523419264279
Prediction: True

Processing sample: TRUST_019c8219-31e2-4bcb-8801-d8248f17040b_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([35, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([35, 19, 768])
Input matrix size: 510720

Making prediction...
Original input shape: torch.Size([35, 19, 768])
Shape after padding: torch.Size([35, 24, 768])
Shape after permute: torch.Size([35, 768, 24])
Shapes after individual convolutions: [torch.Size([35, 3, 1]), torch.Size([35, 2, 1]), torch.Size([35, 1, 1])]
Shape after concatenation: torch.Size([35, 6, 1])
Shape after first reshape: torch.Size([35, 1, 6])
Shape after FC layer and dropout: torch.Size([35, 1, 1])
Shape before final padding: torch.Size([35])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5312398016224816
Prediction: True

Processing sample: TRUST_a6f31fc5-a3bd-400e-abde-64833be445c7_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([44, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([44, 21, 768])
Input matrix size: 709632

Making prediction...
Original input shape: torch.Size([44, 21, 768])
Shape after padding: torch.Size([44, 24, 768])
Shape after permute: torch.Size([44, 768, 24])
Shapes after individual convolutions: [torch.Size([44, 3, 1]), torch.Size([44, 2, 1]), torch.Size([44, 1, 1])]
Shape after concatenation: torch.Size([44, 6, 1])
Shape after first reshape: torch.Size([44, 1, 6])
Shape after FC layer and dropout: torch.Size([44, 1, 1])
Shape before final padding: torch.Size([44])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6589516485985004
Prediction: True

Processing sample: TRUST_77e28dad-a67c-40b7-ac81-f2dbc6c9ebb0_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([35, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([35, 20, 768])
Input matrix size: 537600

Making prediction...
Original input shape: torch.Size([35, 20, 768])
Shape after padding: torch.Size([35, 24, 768])
Shape after permute: torch.Size([35, 768, 24])
Shapes after individual convolutions: [torch.Size([35, 3, 1]), torch.Size([35, 2, 1]), torch.Size([35, 1, 1])]
Shape after concatenation: torch.Size([35, 6, 1])
Shape after first reshape: torch.Size([35, 1, 6])
Shape after FC layer and dropout: torch.Size([35, 1, 1])
Shape before final padding: torch.Size([35])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.629852971044234
Prediction: True

Processing sample: TRUST_b9f688a9-8527-421e-9718-01e7fc611cf8_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([37, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([37, 22, 768])
Input matrix size: 625152

Making prediction...
Original input shape: torch.Size([37, 22, 768])
Shape after padding: torch.Size([37, 24, 768])
Shape after permute: torch.Size([37, 768, 24])
Shapes after individual convolutions: [torch.Size([37, 3, 1]), torch.Size([37, 2, 1]), torch.Size([37, 1, 1])]
Shape after concatenation: torch.Size([37, 6, 1])
Shape after first reshape: torch.Size([37, 1, 6])
Shape after FC layer and dropout: torch.Size([37, 1, 1])
Shape before final padding: torch.Size([37])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5752334018602906
Prediction: True

Processing sample: TRUST_19d2f9a5-9e31-4bbd-965b-7bb4d3b8a53d_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.724769390310967
Prediction: True

Processing sample: TRUST_c898eaac-6844-4061-8165-8084adf665e5_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([12, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([12, 19, 768])
Input matrix size: 175104

Making prediction...
Original input shape: torch.Size([12, 19, 768])
Shape after padding: torch.Size([12, 24, 768])
Shape after permute: torch.Size([12, 768, 24])
Shapes after individual convolutions: [torch.Size([12, 3, 1]), torch.Size([12, 2, 1]), torch.Size([12, 1, 1])]
Shape after concatenation: torch.Size([12, 6, 1])
Shape after first reshape: torch.Size([12, 1, 6])
Shape after FC layer and dropout: torch.Size([12, 1, 1])
Shape before final padding: torch.Size([12])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5262553817435438
Prediction: True

Processing sample: TRUST_fcc0d141-9ca2-47c2-b1c0-4d6753e6fa20_airr_extracted_trb_frequencies_filtered.tsv_batch_8_embedding.pt
Loaded sample shape: torch.Size([7, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([7, 19, 768])
Input matrix size: 102144

Making prediction...
Original input shape: torch.Size([7, 19, 768])
Shape after padding: torch.Size([7, 24, 768])
Shape after permute: torch.Size([7, 768, 24])
Shapes after individual convolutions: [torch.Size([7, 3, 1]), torch.Size([7, 2, 1]), torch.Size([7, 1, 1])]
Shape after concatenation: torch.Size([7, 6, 1])
Shape after first reshape: torch.Size([7, 1, 6])
Shape after FC layer and dropout: torch.Size([7, 1, 1])
Shape before final padding: torch.Size([7])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5298188255989753
Prediction: True

Processing sample: TRUST_fb55ee8e-6211-4009-8ea3-05226bb610ce_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([27, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([27, 21, 768])
Input matrix size: 435456

Making prediction...
Original input shape: torch.Size([27, 21, 768])
Shape after padding: torch.Size([27, 24, 768])
Shape after permute: torch.Size([27, 768, 24])
Shapes after individual convolutions: [torch.Size([27, 3, 1]), torch.Size([27, 2, 1]), torch.Size([27, 1, 1])]
Shape after concatenation: torch.Size([27, 6, 1])
Shape after first reshape: torch.Size([27, 1, 6])
Shape after FC layer and dropout: torch.Size([27, 1, 1])
Shape before final padding: torch.Size([27])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5130288529882593
Prediction: True

Processing sample: TRUST_b5597e1d-07b8-4de4-a1dc-640cde870e9e_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([26, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([26, 23, 768])
Input matrix size: 459264

Making prediction...
Original input shape: torch.Size([26, 23, 768])
Shape after padding: torch.Size([26, 24, 768])
Shape after permute: torch.Size([26, 768, 24])
Shapes after individual convolutions: [torch.Size([26, 3, 1]), torch.Size([26, 2, 1]), torch.Size([26, 1, 1])]
Shape after concatenation: torch.Size([26, 6, 1])
Shape after first reshape: torch.Size([26, 1, 6])
Shape after FC layer and dropout: torch.Size([26, 1, 1])
Shape before final padding: torch.Size([26])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5610466586288952
Prediction: True

Processing sample: TRUST_485beaed-0f45-4d86-9f3e-0ead8bdb844a_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([41, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([41, 22, 768])
Input matrix size: 692736

Making prediction...
Original input shape: torch.Size([41, 22, 768])
Shape after padding: torch.Size([41, 24, 768])
Shape after permute: torch.Size([41, 768, 24])
Shapes after individual convolutions: [torch.Size([41, 3, 1]), torch.Size([41, 2, 1]), torch.Size([41, 1, 1])]
Shape after concatenation: torch.Size([41, 6, 1])
Shape after first reshape: torch.Size([41, 1, 6])
Shape after FC layer and dropout: torch.Size([41, 1, 1])
Shape before final padding: torch.Size([41])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6852928466630807
Prediction: True

Processing sample: TRUST_0c8cd4ea-8477-4e76-9d82-02be4bf16141_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([75, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([75, 21, 768])
Input matrix size: 1209600

Making prediction...
Original input shape: torch.Size([75, 21, 768])
Shape after padding: torch.Size([75, 24, 768])
Shape after permute: torch.Size([75, 768, 24])
Shapes after individual convolutions: [torch.Size([75, 3, 1]), torch.Size([75, 2, 1]), torch.Size([75, 1, 1])]
Shape after concatenation: torch.Size([75, 6, 1])
Shape after first reshape: torch.Size([75, 1, 6])
Shape after FC layer and dropout: torch.Size([75, 1, 1])
Shape before final padding: torch.Size([75])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6195145406035643
Prediction: True

Processing sample: TRUST_3b3b490d-1dd6-40b8-8847-34ff630e159d_airr_extracted_trb_frequencies_filtered.tsv_batch_10_embedding.pt
Loaded sample shape: torch.Size([45, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([45, 20, 768])
Input matrix size: 691200

Making prediction...
Original input shape: torch.Size([45, 20, 768])
Shape after padding: torch.Size([45, 24, 768])
Shape after permute: torch.Size([45, 768, 24])
Shapes after individual convolutions: [torch.Size([45, 3, 1]), torch.Size([45, 2, 1]), torch.Size([45, 1, 1])]
Shape after concatenation: torch.Size([45, 6, 1])
Shape after first reshape: torch.Size([45, 1, 6])
Shape after FC layer and dropout: torch.Size([45, 1, 1])
Shape before final padding: torch.Size([45])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6317568062165263
Prediction: True

Processing sample: TRUST_188ed6a6-092f-44ba-bb16-09a0a15e0864_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([70, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([70, 19, 768])
Input matrix size: 1021440

Making prediction...
Original input shape: torch.Size([70, 19, 768])
Shape after padding: torch.Size([70, 24, 768])
Shape after permute: torch.Size([70, 768, 24])
Shapes after individual convolutions: [torch.Size([70, 3, 1]), torch.Size([70, 2, 1]), torch.Size([70, 1, 1])]
Shape after concatenation: torch.Size([70, 6, 1])
Shape after first reshape: torch.Size([70, 1, 6])
Shape after FC layer and dropout: torch.Size([70, 1, 1])
Shape before final padding: torch.Size([70])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5999010016744238
Prediction: True

Processing sample: TRUST_1989e89c-e7d1-4ee3-931d-bd34fe70e880_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([59, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([59, 20, 768])
Input matrix size: 906240

Making prediction...
Original input shape: torch.Size([59, 20, 768])
Shape after padding: torch.Size([59, 24, 768])
Shape after permute: torch.Size([59, 768, 24])
Shapes after individual convolutions: [torch.Size([59, 3, 1]), torch.Size([59, 2, 1]), torch.Size([59, 1, 1])]
Shape after concatenation: torch.Size([59, 6, 1])
Shape after first reshape: torch.Size([59, 1, 6])
Shape after FC layer and dropout: torch.Size([59, 1, 1])
Shape before final padding: torch.Size([59])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6042038811434787
Prediction: True

Processing sample: TRUST_2a537e43-9cd9-49ae-8174-b28444ca14b5_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([33, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([33, 21, 768])
Input matrix size: 532224

Making prediction...
Original input shape: torch.Size([33, 21, 768])
Shape after padding: torch.Size([33, 24, 768])
Shape after permute: torch.Size([33, 768, 24])
Shapes after individual convolutions: [torch.Size([33, 3, 1]), torch.Size([33, 2, 1]), torch.Size([33, 1, 1])]
Shape after concatenation: torch.Size([33, 6, 1])
Shape after first reshape: torch.Size([33, 1, 6])
Shape after FC layer and dropout: torch.Size([33, 1, 1])
Shape before final padding: torch.Size([33])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6174843227712122
Prediction: True

Processing sample: TRUST_588df35f-35fd-45d9-9ea6-f9b763f99255_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([26, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([26, 19, 768])
Input matrix size: 379392

Making prediction...
Original input shape: torch.Size([26, 19, 768])
Shape after padding: torch.Size([26, 24, 768])
Shape after permute: torch.Size([26, 768, 24])
Shapes after individual convolutions: [torch.Size([26, 3, 1]), torch.Size([26, 2, 1]), torch.Size([26, 1, 1])]
Shape after concatenation: torch.Size([26, 6, 1])
Shape after first reshape: torch.Size([26, 1, 6])
Shape after FC layer and dropout: torch.Size([26, 1, 1])
Shape before final padding: torch.Size([26])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5499123322852595
Prediction: True

Processing sample: TRUST_6a4995f5-588f-4120-9b20-c1ca5bf28c39_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([28, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([28, 20, 768])
Input matrix size: 430080

Making prediction...
Original input shape: torch.Size([28, 20, 768])
Shape after padding: torch.Size([28, 24, 768])
Shape after permute: torch.Size([28, 768, 24])
Shapes after individual convolutions: [torch.Size([28, 3, 1]), torch.Size([28, 2, 1]), torch.Size([28, 1, 1])]
Shape after concatenation: torch.Size([28, 6, 1])
Shape after first reshape: torch.Size([28, 1, 6])
Shape after FC layer and dropout: torch.Size([28, 1, 1])
Shape before final padding: torch.Size([28])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5330851586653087
Prediction: True

Processing sample: TRUST_19d2f9a5-9e31-4bbd-965b-7bb4d3b8a53d_airr_extracted_trb_frequencies_filtered.tsv_batch_5_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.683144028768288
Prediction: True

Processing sample: TRUST_fcc0d141-9ca2-47c2-b1c0-4d6753e6fa20_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 23, 768])
Input matrix size: 1766400

Making prediction...
Original input shape: torch.Size([100, 23, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7244422868729483
Prediction: True

Processing sample: TRUST_2b91021e-82d0-4d5f-a19e-5c52a845bc4f_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([44, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([44, 26, 768])
Input matrix size: 878592

Making prediction...
Original input shape: torch.Size([44, 26, 768])
Shape after permute: torch.Size([44, 768, 26])
Shapes after individual convolutions: [torch.Size([44, 3, 1]), torch.Size([44, 2, 1]), torch.Size([44, 1, 1])]
Shape after concatenation: torch.Size([44, 6, 1])
Shape after first reshape: torch.Size([44, 1, 6])
Shape after FC layer and dropout: torch.Size([44, 1, 1])
Shape before final padding: torch.Size([44])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6595300579433653
Prediction: True

Processing sample: TRUST_315e404a-9e40-4efb-b789-21107326ba69_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([31, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([31, 21, 768])
Input matrix size: 499968

Making prediction...
Original input shape: torch.Size([31, 21, 768])
Shape after padding: torch.Size([31, 24, 768])
Shape after permute: torch.Size([31, 768, 24])
Shapes after individual convolutions: [torch.Size([31, 3, 1]), torch.Size([31, 2, 1]), torch.Size([31, 1, 1])]
Shape after concatenation: torch.Size([31, 6, 1])
Shape after first reshape: torch.Size([31, 1, 6])
Shape after FC layer and dropout: torch.Size([31, 1, 1])
Shape before final padding: torch.Size([31])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4719406142807583
Prediction: False

Processing sample: TRUST_3c383b35-ab5d-4776-906f-551f83fe6af2_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([26, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([26, 22, 768])
Input matrix size: 439296

Making prediction...
Original input shape: torch.Size([26, 22, 768])
Shape after padding: torch.Size([26, 24, 768])
Shape after permute: torch.Size([26, 768, 24])
Shapes after individual convolutions: [torch.Size([26, 3, 1]), torch.Size([26, 2, 1]), torch.Size([26, 1, 1])]
Shape after concatenation: torch.Size([26, 6, 1])
Shape after first reshape: torch.Size([26, 1, 6])
Shape after FC layer and dropout: torch.Size([26, 1, 1])
Shape before final padding: torch.Size([26])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.38306073167117866
Prediction: False

Processing sample: TRUST_1e5ea0dd-c5f0-47c5-a046-bbf759ea7861_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([26, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([26, 19, 768])
Input matrix size: 379392

Making prediction...
Original input shape: torch.Size([26, 19, 768])
Shape after padding: torch.Size([26, 24, 768])
Shape after permute: torch.Size([26, 768, 24])
Shapes after individual convolutions: [torch.Size([26, 3, 1]), torch.Size([26, 2, 1]), torch.Size([26, 1, 1])]
Shape after concatenation: torch.Size([26, 6, 1])
Shape after first reshape: torch.Size([26, 1, 6])
Shape after FC layer and dropout: torch.Size([26, 1, 1])
Shape before final padding: torch.Size([26])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5866952437303522
Prediction: True

Processing sample: TRUST_f2571f49-f938-4285-ae48-3644a2a03529_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7142250410737574
Prediction: True

Processing sample: TRUST_858a7774-a964-41ea-99df-b211b011e6fc_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([41, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([41, 22, 768])
Input matrix size: 692736

Making prediction...
Original input shape: torch.Size([41, 22, 768])
Shape after padding: torch.Size([41, 24, 768])
Shape after permute: torch.Size([41, 768, 24])
Shapes after individual convolutions: [torch.Size([41, 3, 1]), torch.Size([41, 2, 1]), torch.Size([41, 1, 1])]
Shape after concatenation: torch.Size([41, 6, 1])
Shape after first reshape: torch.Size([41, 1, 6])
Shape after FC layer and dropout: torch.Size([41, 1, 1])
Shape before final padding: torch.Size([41])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6651061745569601
Prediction: True

Processing sample: TRUST_c73e4096-f96e-42c0-8b0e-6ccba77c3574_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([30, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([30, 26, 768])
Input matrix size: 599040

Making prediction...
Original input shape: torch.Size([30, 26, 768])
Shape after permute: torch.Size([30, 768, 26])
Shapes after individual convolutions: [torch.Size([30, 3, 1]), torch.Size([30, 2, 1]), torch.Size([30, 1, 1])]
Shape after concatenation: torch.Size([30, 6, 1])
Shape after first reshape: torch.Size([30, 1, 6])
Shape after FC layer and dropout: torch.Size([30, 1, 1])
Shape before final padding: torch.Size([30])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5139244245501202
Prediction: True

Processing sample: TRUST_e6a99fe5-615e-44ae-963c-8e008b5e51cd_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([94, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([94, 21, 768])
Input matrix size: 1516032

Making prediction...
Original input shape: torch.Size([94, 21, 768])
Shape after padding: torch.Size([94, 24, 768])
Shape after permute: torch.Size([94, 768, 24])
Shapes after individual convolutions: [torch.Size([94, 3, 1]), torch.Size([94, 2, 1]), torch.Size([94, 1, 1])]
Shape after concatenation: torch.Size([94, 6, 1])
Shape after first reshape: torch.Size([94, 1, 6])
Shape after FC layer and dropout: torch.Size([94, 1, 1])
Shape before final padding: torch.Size([94])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7135531031812669
Prediction: True

Processing sample: TRUST_12910156-b333-4c54-ab32-4adf9dfac3f7_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([56, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([56, 21, 768])
Input matrix size: 903168

Making prediction...
Original input shape: torch.Size([56, 21, 768])
Shape after padding: torch.Size([56, 24, 768])
Shape after permute: torch.Size([56, 768, 24])
Shapes after individual convolutions: [torch.Size([56, 3, 1]), torch.Size([56, 2, 1]), torch.Size([56, 1, 1])]
Shape after concatenation: torch.Size([56, 6, 1])
Shape after first reshape: torch.Size([56, 1, 6])
Shape after FC layer and dropout: torch.Size([56, 1, 1])
Shape before final padding: torch.Size([56])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.44294378807322504
Prediction: False

Processing sample: TRUST_19d2f9a5-9e31-4bbd-965b-7bb4d3b8a53d_airr_extracted_trb_frequencies_filtered.tsv_batch_9_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.3870222114891227
Prediction: False

Processing sample: TRUST_3b3b490d-1dd6-40b8-8847-34ff630e159d_airr_extracted_trb_frequencies_filtered.tsv_batch_6_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7163567683016476
Prediction: True

Processing sample: TRUST_cb5f41e0-b340-41f0-b15b-77a7724a2223_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([81, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([81, 23, 768])
Input matrix size: 1430784

Making prediction...
Original input shape: torch.Size([81, 23, 768])
Shape after padding: torch.Size([81, 24, 768])
Shape after permute: torch.Size([81, 768, 24])
Shapes after individual convolutions: [torch.Size([81, 3, 1]), torch.Size([81, 2, 1]), torch.Size([81, 1, 1])]
Shape after concatenation: torch.Size([81, 6, 1])
Shape after first reshape: torch.Size([81, 1, 6])
Shape after FC layer and dropout: torch.Size([81, 1, 1])
Shape before final padding: torch.Size([81])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5336028592400553
Prediction: True

Processing sample: TRUST_e97d15f7-adcf-4c00-b432-fc84e51ef909_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([69, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([69, 22, 768])
Input matrix size: 1165824

Making prediction...
Original input shape: torch.Size([69, 22, 768])
Shape after padding: torch.Size([69, 24, 768])
Shape after permute: torch.Size([69, 768, 24])
Shapes after individual convolutions: [torch.Size([69, 3, 1]), torch.Size([69, 2, 1]), torch.Size([69, 1, 1])]
Shape after concatenation: torch.Size([69, 6, 1])
Shape after first reshape: torch.Size([69, 1, 6])
Shape after FC layer and dropout: torch.Size([69, 1, 1])
Shape before final padding: torch.Size([69])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4710025879734865
Prediction: False

Processing sample: TRUST_9f7f93d0-c241-41d6-8217-eb35e2b3a454_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([49, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([49, 22, 768])
Input matrix size: 827904

Making prediction...
Original input shape: torch.Size([49, 22, 768])
Shape after padding: torch.Size([49, 24, 768])
Shape after permute: torch.Size([49, 768, 24])
Shapes after individual convolutions: [torch.Size([49, 3, 1]), torch.Size([49, 2, 1]), torch.Size([49, 1, 1])]
Shape after concatenation: torch.Size([49, 6, 1])
Shape after first reshape: torch.Size([49, 1, 6])
Shape after FC layer and dropout: torch.Size([49, 1, 1])
Shape before final padding: torch.Size([49])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6535372409919845
Prediction: True

Processing sample: TRUST_07a5f6c9-f40b-4636-b3c2-6970f51afb89_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([29, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([29, 19, 768])
Input matrix size: 423168

Making prediction...
Original input shape: torch.Size([29, 19, 768])
Shape after padding: torch.Size([29, 24, 768])
Shape after permute: torch.Size([29, 768, 24])
Shapes after individual convolutions: [torch.Size([29, 3, 1]), torch.Size([29, 2, 1]), torch.Size([29, 1, 1])]
Shape after concatenation: torch.Size([29, 6, 1])
Shape after first reshape: torch.Size([29, 1, 6])
Shape after FC layer and dropout: torch.Size([29, 1, 1])
Shape before final padding: torch.Size([29])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.44911532666340304
Prediction: False

Processing sample: TRUST_65854bfb-5d68-4d10-85d5-d2e1459da8f6_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6952267295960799
Prediction: True

Processing sample: TRUST_34d3a189-b243-4870-b887-a3fc627b037d_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([33, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([33, 22, 768])
Input matrix size: 557568

Making prediction...
Original input shape: torch.Size([33, 22, 768])
Shape after padding: torch.Size([33, 24, 768])
Shape after permute: torch.Size([33, 768, 24])
Shapes after individual convolutions: [torch.Size([33, 3, 1]), torch.Size([33, 2, 1]), torch.Size([33, 1, 1])]
Shape after concatenation: torch.Size([33, 6, 1])
Shape after first reshape: torch.Size([33, 1, 6])
Shape after FC layer and dropout: torch.Size([33, 1, 1])
Shape before final padding: torch.Size([33])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6717496521130919
Prediction: True

Processing sample: TRUST_f247c909-3278-4b1e-983f-833276dc8be0_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4488735496833184
Prediction: False

Processing sample: TRUST_fcc0d141-9ca2-47c2-b1c0-4d6753e6fa20_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7198084993633034
Prediction: True

Processing sample: TRUST_e575d12f-4f1a-49ba-a067-6c174a9b4149_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([35, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([35, 20, 768])
Input matrix size: 537600

Making prediction...
Original input shape: torch.Size([35, 20, 768])
Shape after padding: torch.Size([35, 24, 768])
Shape after permute: torch.Size([35, 768, 24])
Shapes after individual convolutions: [torch.Size([35, 3, 1]), torch.Size([35, 2, 1]), torch.Size([35, 1, 1])]
Shape after concatenation: torch.Size([35, 6, 1])
Shape after first reshape: torch.Size([35, 1, 6])
Shape after FC layer and dropout: torch.Size([35, 1, 1])
Shape before final padding: torch.Size([35])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.41304797596684373
Prediction: False

Processing sample: TRUST_bf3bf105-7689-46a5-be27-8e887e4b4eaf_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([43, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([43, 23, 768])
Input matrix size: 759552

Making prediction...
Original input shape: torch.Size([43, 23, 768])
Shape after padding: torch.Size([43, 24, 768])
Shape after permute: torch.Size([43, 768, 24])
Shapes after individual convolutions: [torch.Size([43, 3, 1]), torch.Size([43, 2, 1]), torch.Size([43, 1, 1])]
Shape after concatenation: torch.Size([43, 6, 1])
Shape after first reshape: torch.Size([43, 1, 6])
Shape after FC layer and dropout: torch.Size([43, 1, 1])
Shape before final padding: torch.Size([43])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6948399295484929
Prediction: True

Processing sample: TRUST_98fa6e05-b441-4287-aa6c-062012f2de98_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([83, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([83, 26, 768])
Input matrix size: 1657344

Making prediction...
Original input shape: torch.Size([83, 26, 768])
Shape after permute: torch.Size([83, 768, 26])
Shapes after individual convolutions: [torch.Size([83, 3, 1]), torch.Size([83, 2, 1]), torch.Size([83, 1, 1])]
Shape after concatenation: torch.Size([83, 6, 1])
Shape after first reshape: torch.Size([83, 1, 6])
Shape after FC layer and dropout: torch.Size([83, 1, 1])
Shape before final padding: torch.Size([83])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6806597155449061
Prediction: True

Processing sample: TRUST_d2428a32-6b39-45d4-88bc-fc6b35a633c2_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([46, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([46, 26, 768])
Input matrix size: 918528

Making prediction...
Original input shape: torch.Size([46, 26, 768])
Shape after permute: torch.Size([46, 768, 26])
Shapes after individual convolutions: [torch.Size([46, 3, 1]), torch.Size([46, 2, 1]), torch.Size([46, 1, 1])]
Shape after concatenation: torch.Size([46, 6, 1])
Shape after first reshape: torch.Size([46, 1, 6])
Shape after FC layer and dropout: torch.Size([46, 1, 1])
Shape before final padding: torch.Size([46])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5783643134886357
Prediction: True

Processing sample: TRUST_404024d4-f8e8-454c-9ded-93e82fe747eb_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([25, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([25, 19, 768])
Input matrix size: 364800

Making prediction...
Original input shape: torch.Size([25, 19, 768])
Shape after padding: torch.Size([25, 24, 768])
Shape after permute: torch.Size([25, 768, 24])
Shapes after individual convolutions: [torch.Size([25, 3, 1]), torch.Size([25, 2, 1]), torch.Size([25, 1, 1])]
Shape after concatenation: torch.Size([25, 6, 1])
Shape after first reshape: torch.Size([25, 1, 6])
Shape after FC layer and dropout: torch.Size([25, 1, 1])
Shape before final padding: torch.Size([25])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5018920510103205
Prediction: True

Processing sample: TRUST_f3e3b17e-65c3-4bd4-a895-7a5bad8c6630_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([26, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([26, 20, 768])
Input matrix size: 399360

Making prediction...
Original input shape: torch.Size([26, 20, 768])
Shape after padding: torch.Size([26, 24, 768])
Shape after permute: torch.Size([26, 768, 24])
Shapes after individual convolutions: [torch.Size([26, 3, 1]), torch.Size([26, 2, 1]), torch.Size([26, 1, 1])]
Shape after concatenation: torch.Size([26, 6, 1])
Shape after first reshape: torch.Size([26, 1, 6])
Shape after FC layer and dropout: torch.Size([26, 1, 1])
Shape before final padding: torch.Size([26])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5327085598227356
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_20_embedding.pt
Loaded sample shape: torch.Size([100, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 20, 768])
Input matrix size: 1536000

Making prediction...
Original input shape: torch.Size([100, 20, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6510218662570583
Prediction: True

Processing sample: TRUST_19d2f9a5-9e31-4bbd-965b-7bb4d3b8a53d_airr_extracted_trb_frequencies_filtered.tsv_batch_3_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7170346906913521
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_18_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6594620761435537
Prediction: True

Processing sample: TRUST_8d1f39e1-e2e7-442a-bc88-d1d54d907fb7_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([43, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([43, 20, 768])
Input matrix size: 660480

Making prediction...
Original input shape: torch.Size([43, 20, 768])
Shape after padding: torch.Size([43, 24, 768])
Shape after permute: torch.Size([43, 768, 24])
Shapes after individual convolutions: [torch.Size([43, 3, 1]), torch.Size([43, 2, 1]), torch.Size([43, 1, 1])]
Shape after concatenation: torch.Size([43, 6, 1])
Shape after first reshape: torch.Size([43, 1, 6])
Shape after FC layer and dropout: torch.Size([43, 1, 1])
Shape before final padding: torch.Size([43])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6799508633030417
Prediction: True

Processing sample: TRUST_cc79d1ad-4ef8-4d3a-abfa-06b38ef3f8ab_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([46, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([46, 22, 768])
Input matrix size: 777216

Making prediction...
Original input shape: torch.Size([46, 22, 768])
Shape after padding: torch.Size([46, 24, 768])
Shape after permute: torch.Size([46, 768, 24])
Shapes after individual convolutions: [torch.Size([46, 3, 1]), torch.Size([46, 2, 1]), torch.Size([46, 1, 1])]
Shape after concatenation: torch.Size([46, 6, 1])
Shape after first reshape: torch.Size([46, 1, 6])
Shape after FC layer and dropout: torch.Size([46, 1, 1])
Shape before final padding: torch.Size([46])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4537017708981023
Prediction: False

Processing sample: TRUST_1e7a9e1f-c900-465e-a27c-1e1e9b3af1c4_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([34, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([34, 26, 768])
Input matrix size: 678912

Making prediction...
Original input shape: torch.Size([34, 26, 768])
Shape after permute: torch.Size([34, 768, 26])
Shapes after individual convolutions: [torch.Size([34, 3, 1]), torch.Size([34, 2, 1]), torch.Size([34, 1, 1])]
Shape after concatenation: torch.Size([34, 6, 1])
Shape after first reshape: torch.Size([34, 1, 6])
Shape after FC layer and dropout: torch.Size([34, 1, 1])
Shape before final padding: torch.Size([34])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4038186954986099
Prediction: False

Processing sample: TRUST_6255546c-2d10-47d3-b67a-d035382b8fb9_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([43, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([43, 20, 768])
Input matrix size: 660480

Making prediction...
Original input shape: torch.Size([43, 20, 768])
Shape after padding: torch.Size([43, 24, 768])
Shape after permute: torch.Size([43, 768, 24])
Shapes after individual convolutions: [torch.Size([43, 3, 1]), torch.Size([43, 2, 1]), torch.Size([43, 1, 1])]
Shape after concatenation: torch.Size([43, 6, 1])
Shape after first reshape: torch.Size([43, 1, 6])
Shape after FC layer and dropout: torch.Size([43, 1, 1])
Shape before final padding: torch.Size([43])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.661685772067319
Prediction: True

Processing sample: TRUST_1619a994-99b2-4000-b214-cc6906d4e23a_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([86, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([86, 23, 768])
Input matrix size: 1519104

Making prediction...
Original input shape: torch.Size([86, 23, 768])
Shape after padding: torch.Size([86, 24, 768])
Shape after permute: torch.Size([86, 768, 24])
Shapes after individual convolutions: [torch.Size([86, 3, 1]), torch.Size([86, 2, 1]), torch.Size([86, 1, 1])]
Shape after concatenation: torch.Size([86, 6, 1])
Shape after first reshape: torch.Size([86, 1, 6])
Shape after FC layer and dropout: torch.Size([86, 1, 1])
Shape before final padding: torch.Size([86])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6716545295614991
Prediction: True

Processing sample: TRUST_1810358e-9ab4-45b4-baf9-0f83b29f692b_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([37, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([37, 22, 768])
Input matrix size: 625152

Making prediction...
Original input shape: torch.Size([37, 22, 768])
Shape after padding: torch.Size([37, 24, 768])
Shape after permute: torch.Size([37, 768, 24])
Shapes after individual convolutions: [torch.Size([37, 3, 1]), torch.Size([37, 2, 1]), torch.Size([37, 1, 1])]
Shape after concatenation: torch.Size([37, 6, 1])
Shape after first reshape: torch.Size([37, 1, 6])
Shape after FC layer and dropout: torch.Size([37, 1, 1])
Shape before final padding: torch.Size([37])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6404127414427531
Prediction: True

Processing sample: TRUST_27042bff-53b3-45d6-834c-a59ec580d451_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([53, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([53, 21, 768])
Input matrix size: 854784

Making prediction...
Original input shape: torch.Size([53, 21, 768])
Shape after padding: torch.Size([53, 24, 768])
Shape after permute: torch.Size([53, 768, 24])
Shapes after individual convolutions: [torch.Size([53, 3, 1]), torch.Size([53, 2, 1]), torch.Size([53, 1, 1])]
Shape after concatenation: torch.Size([53, 6, 1])
Shape after first reshape: torch.Size([53, 1, 6])
Shape after FC layer and dropout: torch.Size([53, 1, 1])
Shape before final padding: torch.Size([53])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6251008871435016
Prediction: True

Processing sample: TRUST_6e42c897-be8b-490c-8cb2-e9495610b10d_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([88, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([88, 20, 768])
Input matrix size: 1351680

Making prediction...
Original input shape: torch.Size([88, 20, 768])
Shape after padding: torch.Size([88, 24, 768])
Shape after permute: torch.Size([88, 768, 24])
Shapes after individual convolutions: [torch.Size([88, 3, 1]), torch.Size([88, 2, 1]), torch.Size([88, 1, 1])]
Shape after concatenation: torch.Size([88, 6, 1])
Shape after first reshape: torch.Size([88, 1, 6])
Shape after FC layer and dropout: torch.Size([88, 1, 1])
Shape before final padding: torch.Size([88])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7006499886684572
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_31_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5153065611852892
Prediction: True

Processing sample: TRUST_f0cf56e0-42a4-41fd-b233-352c756eae62_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.712853928785831
Prediction: True

Processing sample: TRUST_69579b46-713e-4b83-b4a6-eed6b1da6c0d_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([63, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([63, 21, 768])
Input matrix size: 1016064

Making prediction...
Original input shape: torch.Size([63, 21, 768])
Shape after padding: torch.Size([63, 24, 768])
Shape after permute: torch.Size([63, 768, 24])
Shapes after individual convolutions: [torch.Size([63, 3, 1]), torch.Size([63, 2, 1]), torch.Size([63, 1, 1])]
Shape after concatenation: torch.Size([63, 6, 1])
Shape after first reshape: torch.Size([63, 1, 6])
Shape after FC layer and dropout: torch.Size([63, 1, 1])
Shape before final padding: torch.Size([63])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6364702349694547
Prediction: True

Processing sample: TRUST_4501df29-a8eb-454e-b37f-235591e01688_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([87, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([87, 26, 768])
Input matrix size: 1737216

Making prediction...
Original input shape: torch.Size([87, 26, 768])
Shape after permute: torch.Size([87, 768, 26])
Shapes after individual convolutions: [torch.Size([87, 3, 1]), torch.Size([87, 2, 1]), torch.Size([87, 1, 1])]
Shape after concatenation: torch.Size([87, 6, 1])
Shape after first reshape: torch.Size([87, 1, 6])
Shape after FC layer and dropout: torch.Size([87, 1, 1])
Shape before final padding: torch.Size([87])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5908049912553837
Prediction: True

Processing sample: TRUST_80f5cdc8-e9ba-4fe6-a278-2156b9ebccb2_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([43, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([43, 20, 768])
Input matrix size: 660480

Making prediction...
Original input shape: torch.Size([43, 20, 768])
Shape after padding: torch.Size([43, 24, 768])
Shape after permute: torch.Size([43, 768, 24])
Shapes after individual convolutions: [torch.Size([43, 3, 1]), torch.Size([43, 2, 1]), torch.Size([43, 1, 1])]
Shape after concatenation: torch.Size([43, 6, 1])
Shape after first reshape: torch.Size([43, 1, 6])
Shape after FC layer and dropout: torch.Size([43, 1, 1])
Shape before final padding: torch.Size([43])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.46137552651092995
Prediction: False

Processing sample: TRUST_ca8d7caa-0fd5-4553-a38a-45faf1e138cb_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([10, 18, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([10, 18, 768])
Input matrix size: 138240

Making prediction...
Original input shape: torch.Size([10, 18, 768])
Shape after padding: torch.Size([10, 24, 768])
Shape after permute: torch.Size([10, 768, 24])
Shapes after individual convolutions: [torch.Size([10, 3, 1]), torch.Size([10, 2, 1]), torch.Size([10, 1, 1])]
Shape after concatenation: torch.Size([10, 6, 1])
Shape after first reshape: torch.Size([10, 1, 6])
Shape after FC layer and dropout: torch.Size([10, 1, 1])
Shape before final padding: torch.Size([10])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5226719818291845
Prediction: True

Processing sample: TRUST_f2571f49-f938-4285-ae48-3644a2a03529_airr_extracted_trb_frequencies_filtered.tsv_batch_3_embedding.pt
Loaded sample shape: torch.Size([34, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([34, 21, 768])
Input matrix size: 548352

Making prediction...
Original input shape: torch.Size([34, 21, 768])
Shape after padding: torch.Size([34, 24, 768])
Shape after permute: torch.Size([34, 768, 24])
Shapes after individual convolutions: [torch.Size([34, 3, 1]), torch.Size([34, 2, 1]), torch.Size([34, 1, 1])]
Shape after concatenation: torch.Size([34, 6, 1])
Shape after first reshape: torch.Size([34, 1, 6])
Shape after FC layer and dropout: torch.Size([34, 1, 1])
Shape before final padding: torch.Size([34])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5687723180106404
Prediction: True

Processing sample: TRUST_2c5497dc-1e90-40a1-9c75-a002a6664075_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([26, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([26, 19, 768])
Input matrix size: 379392

Making prediction...
Original input shape: torch.Size([26, 19, 768])
Shape after padding: torch.Size([26, 24, 768])
Shape after permute: torch.Size([26, 768, 24])
Shapes after individual convolutions: [torch.Size([26, 3, 1]), torch.Size([26, 2, 1]), torch.Size([26, 1, 1])]
Shape after concatenation: torch.Size([26, 6, 1])
Shape after first reshape: torch.Size([26, 1, 6])
Shape after FC layer and dropout: torch.Size([26, 1, 1])
Shape before final padding: torch.Size([26])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5136880638723437
Prediction: True

Processing sample: TRUST_5c9a5c7b-fdce-414c-9fb4-0b7b1e5078b5_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([63, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([63, 22, 768])
Input matrix size: 1064448

Making prediction...
Original input shape: torch.Size([63, 22, 768])
Shape after padding: torch.Size([63, 24, 768])
Shape after permute: torch.Size([63, 768, 24])
Shapes after individual convolutions: [torch.Size([63, 3, 1]), torch.Size([63, 2, 1]), torch.Size([63, 1, 1])]
Shape after concatenation: torch.Size([63, 6, 1])
Shape after first reshape: torch.Size([63, 1, 6])
Shape after FC layer and dropout: torch.Size([63, 1, 1])
Shape before final padding: torch.Size([63])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6905515971498435
Prediction: True

Processing sample: TRUST_84f66a53-029b-4727-bb2e-93c38541494f_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 26, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 26, 768])
Input matrix size: 1996800

Making prediction...
Original input shape: torch.Size([100, 26, 768])
Shape after permute: torch.Size([100, 768, 26])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6268537717723148
Prediction: True

Processing sample: TRUST_6718d792-5cbe-436e-9f6e-428de03ac9f8_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([25, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([25, 21, 768])
Input matrix size: 403200

Making prediction...
Original input shape: torch.Size([25, 21, 768])
Shape after padding: torch.Size([25, 24, 768])
Shape after permute: torch.Size([25, 768, 24])
Shapes after individual convolutions: [torch.Size([25, 3, 1]), torch.Size([25, 2, 1]), torch.Size([25, 1, 1])]
Shape after concatenation: torch.Size([25, 6, 1])
Shape after first reshape: torch.Size([25, 1, 6])
Shape after FC layer and dropout: torch.Size([25, 1, 1])
Shape before final padding: torch.Size([25])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4333359070924709
Prediction: False

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_14_embedding.pt
Loaded sample shape: torch.Size([100, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 20, 768])
Input matrix size: 1536000

Making prediction...
Original input shape: torch.Size([100, 20, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6806887487669543
Prediction: True

Processing sample: TRUST_ad4471ef-5078-4602-a4b3-3cda3f41b1d6_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([40, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([40, 22, 768])
Input matrix size: 675840

Making prediction...
Original input shape: torch.Size([40, 22, 768])
Shape after padding: torch.Size([40, 24, 768])
Shape after permute: torch.Size([40, 768, 24])
Shapes after individual convolutions: [torch.Size([40, 3, 1]), torch.Size([40, 2, 1]), torch.Size([40, 1, 1])]
Shape after concatenation: torch.Size([40, 6, 1])
Shape after first reshape: torch.Size([40, 1, 6])
Shape after FC layer and dropout: torch.Size([40, 1, 1])
Shape before final padding: torch.Size([40])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6314291648678122
Prediction: True

Processing sample: TRUST_8ee166fd-2907-413c-b26f-3ed0a4f8fab8_airr_extracted_trb_frequencies_filtered.tsv_batch_10_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5269894417896328
Prediction: True

Processing sample: TRUST_66b732fb-e4c8-44fd-889c-7c5a48f8b0d3_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([59, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([59, 20, 768])
Input matrix size: 906240

Making prediction...
Original input shape: torch.Size([59, 20, 768])
Shape after padding: torch.Size([59, 24, 768])
Shape after permute: torch.Size([59, 768, 24])
Shapes after individual convolutions: [torch.Size([59, 3, 1]), torch.Size([59, 2, 1]), torch.Size([59, 1, 1])]
Shape after concatenation: torch.Size([59, 6, 1])
Shape after first reshape: torch.Size([59, 1, 6])
Shape after FC layer and dropout: torch.Size([59, 1, 1])
Shape before final padding: torch.Size([59])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.593841682836424
Prediction: True

Processing sample: TRUST_3b3b490d-1dd6-40b8-8847-34ff630e159d_airr_extracted_trb_frequencies_filtered.tsv_batch_4_embedding.pt
Loaded sample shape: torch.Size([100, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 23, 768])
Input matrix size: 1766400

Making prediction...
Original input shape: torch.Size([100, 23, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.7175960858711141
Prediction: True

Processing sample: TRUST_7bc2d53d-cd8a-48b2-b163-d18d0e2a5f85_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([34, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([34, 21, 768])
Input matrix size: 548352

Making prediction...
Original input shape: torch.Size([34, 21, 768])
Shape after padding: torch.Size([34, 24, 768])
Shape after permute: torch.Size([34, 768, 24])
Shapes after individual convolutions: [torch.Size([34, 3, 1]), torch.Size([34, 2, 1]), torch.Size([34, 1, 1])]
Shape after concatenation: torch.Size([34, 6, 1])
Shape after first reshape: torch.Size([34, 1, 6])
Shape after FC layer and dropout: torch.Size([34, 1, 1])
Shape before final padding: torch.Size([34])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4811160798221034
Prediction: False

Processing sample: TRUST_fcc0d141-9ca2-47c2-b1c0-4d6753e6fa20_airr_extracted_trb_frequencies_filtered.tsv_batch_4_embedding.pt
Loaded sample shape: torch.Size([100, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 22, 768])
Input matrix size: 1689600

Making prediction...
Original input shape: torch.Size([100, 22, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6992800163326754
Prediction: True

Processing sample: TRUST_a262a310-26a2-43a6-bc7f-52a32c29687a_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([28, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([28, 20, 768])
Input matrix size: 430080

Making prediction...
Original input shape: torch.Size([28, 20, 768])
Shape after padding: torch.Size([28, 24, 768])
Shape after permute: torch.Size([28, 768, 24])
Shapes after individual convolutions: [torch.Size([28, 3, 1]), torch.Size([28, 2, 1]), torch.Size([28, 1, 1])]
Shape after concatenation: torch.Size([28, 6, 1])
Shape after first reshape: torch.Size([28, 1, 6])
Shape after FC layer and dropout: torch.Size([28, 1, 1])
Shape before final padding: torch.Size([28])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.619197463314608
Prediction: True

Processing sample: TRUST_96702430-a3ce-4831-9ab8-6fa4bb043d4b_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([25, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([25, 21, 768])
Input matrix size: 403200

Making prediction...
Original input shape: torch.Size([25, 21, 768])
Shape after padding: torch.Size([25, 24, 768])
Shape after permute: torch.Size([25, 768, 24])
Shapes after individual convolutions: [torch.Size([25, 3, 1]), torch.Size([25, 2, 1]), torch.Size([25, 1, 1])]
Shape after concatenation: torch.Size([25, 6, 1])
Shape after first reshape: torch.Size([25, 1, 6])
Shape after FC layer and dropout: torch.Size([25, 1, 1])
Shape before final padding: torch.Size([25])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5728237808123636
Prediction: True

Processing sample: TRUST_efb51ed1-9cae-4228-ae90-880489dc933b_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([77, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([77, 22, 768])
Input matrix size: 1300992

Making prediction...
Original input shape: torch.Size([77, 22, 768])
Shape after padding: torch.Size([77, 24, 768])
Shape after permute: torch.Size([77, 768, 24])
Shapes after individual convolutions: [torch.Size([77, 3, 1]), torch.Size([77, 2, 1]), torch.Size([77, 1, 1])]
Shape after concatenation: torch.Size([77, 6, 1])
Shape after first reshape: torch.Size([77, 1, 6])
Shape after FC layer and dropout: torch.Size([77, 1, 1])
Shape before final padding: torch.Size([77])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6931050833532324
Prediction: True

Processing sample: TRUST_2c1256e6-3f87-4943-8463-b8983ab78e5d_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([26, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([26, 19, 768])
Input matrix size: 379392

Making prediction...
Original input shape: torch.Size([26, 19, 768])
Shape after padding: torch.Size([26, 24, 768])
Shape after permute: torch.Size([26, 768, 24])
Shapes after individual convolutions: [torch.Size([26, 3, 1]), torch.Size([26, 2, 1]), torch.Size([26, 1, 1])]
Shape after concatenation: torch.Size([26, 6, 1])
Shape after first reshape: torch.Size([26, 1, 6])
Shape after FC layer and dropout: torch.Size([26, 1, 1])
Shape before final padding: torch.Size([26])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5108733391512558
Prediction: True

Processing sample: TRUST_cf3ce199-3539-4bd3-9463-e51b5385c3a5_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([38, 23, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([38, 23, 768])
Input matrix size: 671232

Making prediction...
Original input shape: torch.Size([38, 23, 768])
Shape after padding: torch.Size([38, 24, 768])
Shape after permute: torch.Size([38, 768, 24])
Shapes after individual convolutions: [torch.Size([38, 3, 1]), torch.Size([38, 2, 1]), torch.Size([38, 1, 1])]
Shape after concatenation: torch.Size([38, 6, 1])
Shape after first reshape: torch.Size([38, 1, 6])
Shape after FC layer and dropout: torch.Size([38, 1, 1])
Shape before final padding: torch.Size([38])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4586334300206151
Prediction: False

Processing sample: TRUST_168fa135-546d-4878-81e0-cab85c315236_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([27, 20, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([27, 20, 768])
Input matrix size: 414720

Making prediction...
Original input shape: torch.Size([27, 20, 768])
Shape after padding: torch.Size([27, 24, 768])
Shape after permute: torch.Size([27, 768, 24])
Shapes after individual convolutions: [torch.Size([27, 3, 1]), torch.Size([27, 2, 1]), torch.Size([27, 1, 1])]
Shape after concatenation: torch.Size([27, 6, 1])
Shape after first reshape: torch.Size([27, 1, 6])
Shape after FC layer and dropout: torch.Size([27, 1, 1])
Shape before final padding: torch.Size([27])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.5387869596525556
Prediction: True

Processing sample: TRUST_fcf29edc-a464-42f8-8ed4-ac56d5c39bbf_airr_extracted_trb_frequencies_filtered.tsv_batch_3_embedding.pt
Loaded sample shape: torch.Size([94, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([94, 21, 768])
Input matrix size: 1516032

Making prediction...
Original input shape: torch.Size([94, 21, 768])
Shape after padding: torch.Size([94, 24, 768])
Shape after permute: torch.Size([94, 768, 24])
Shapes after individual convolutions: [torch.Size([94, 3, 1]), torch.Size([94, 2, 1]), torch.Size([94, 1, 1])]
Shape after concatenation: torch.Size([94, 6, 1])
Shape after first reshape: torch.Size([94, 1, 6])
Shape after FC layer and dropout: torch.Size([94, 1, 1])
Shape before final padding: torch.Size([94])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.715218747391792
Prediction: True

Processing sample: TRUST_7e4d321b-6fad-4f69-90e6-d146dc80a752_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([28, 19, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([28, 19, 768])
Input matrix size: 408576

Making prediction...
Original input shape: torch.Size([28, 19, 768])
Shape after padding: torch.Size([28, 24, 768])
Shape after permute: torch.Size([28, 768, 24])
Shapes after individual convolutions: [torch.Size([28, 3, 1]), torch.Size([28, 2, 1]), torch.Size([28, 1, 1])]
Shape after concatenation: torch.Size([28, 6, 1])
Shape after first reshape: torch.Size([28, 1, 6])
Shape after FC layer and dropout: torch.Size([28, 1, 1])
Shape before final padding: torch.Size([28])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6256628180164113
Prediction: True

Processing sample: TRUST_3b3b490d-1dd6-40b8-8847-34ff630e159d_airr_extracted_trb_frequencies_filtered.tsv_batch_3_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.694848953301275
Prediction: True

Processing sample: TRUST_e18195a1-f04d-4270-ac12-6b4e3accf8a1_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6059023849298479
Prediction: True

Processing sample: TRUST_188ed6a6-092f-44ba-bb16-09a0a15e0864_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([100, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([100, 21, 768])
Input matrix size: 1612800

Making prediction...
Original input shape: torch.Size([100, 21, 768])
Shape after padding: torch.Size([100, 24, 768])
Shape after permute: torch.Size([100, 768, 24])
Shapes after individual convolutions: [torch.Size([100, 3, 1]), torch.Size([100, 2, 1]), torch.Size([100, 1, 1])]
Shape after concatenation: torch.Size([100, 6, 1])
Shape after first reshape: torch.Size([100, 1, 6])
Shape after FC layer and dropout: torch.Size([100, 1, 1])
Shape before final padding: torch.Size([100])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6777252987514358
Prediction: True

Processing sample: TRUST_553c3345-249f-4922-9f8a-2cc126c95c64_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([26, 22, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([26, 22, 768])
Input matrix size: 439296

Making prediction...
Original input shape: torch.Size([26, 22, 768])
Shape after padding: torch.Size([26, 24, 768])
Shape after permute: torch.Size([26, 768, 24])
Shapes after individual convolutions: [torch.Size([26, 3, 1]), torch.Size([26, 2, 1]), torch.Size([26, 1, 1])]
Shape after concatenation: torch.Size([26, 6, 1])
Shape after first reshape: torch.Size([26, 1, 6])
Shape after FC layer and dropout: torch.Size([26, 1, 1])
Shape before final padding: torch.Size([26])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.537486027490799
Prediction: True

Processing sample: TRUST_255b9298-934b-428e-9b36-3b5ff063b41e_airr_extracted_trb_frequencies_filtered.tsv_batch_1_embedding.pt
Loaded sample shape: torch.Size([27, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([27, 21, 768])
Input matrix size: 435456

Making prediction...
Original input shape: torch.Size([27, 21, 768])
Shape after padding: torch.Size([27, 24, 768])
Shape after permute: torch.Size([27, 768, 24])
Shapes after individual convolutions: [torch.Size([27, 3, 1]), torch.Size([27, 2, 1]), torch.Size([27, 1, 1])]
Shape after concatenation: torch.Size([27, 6, 1])
Shape after first reshape: torch.Size([27, 1, 6])
Shape after FC layer and dropout: torch.Size([27, 1, 1])
Shape before final padding: torch.Size([27])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.6295156489073602
Prediction: True

Processing sample: TRUST_f30b60ce-703a-4608-aad6-b1673a1b016b_airr_extracted_trb_frequencies_filtered.tsv_batch_2_embedding.pt
Loaded sample shape: torch.Size([13, 21, 768])
Sample dtype: torch.float32
Sample device: cpu
Sample moved to device: cuda:0
Input matrix shape: torch.Size([13, 21, 768])
Input matrix size: 209664

Making prediction...
Original input shape: torch.Size([13, 21, 768])
Shape after padding: torch.Size([13, 24, 768])
Shape after permute: torch.Size([13, 768, 24])
Shapes after individual convolutions: [torch.Size([13, 3, 1]), torch.Size([13, 2, 1]), torch.Size([13, 1, 1])]
Shape after concatenation: torch.Size([13, 6, 1])
Shape after first reshape: torch.Size([13, 1, 6])
Shape after FC layer and dropout: torch.Size([13, 1, 1])
Shape before final padding: torch.Size([13])
Shape after final reshape: torch.Size([1, 100])
Shape after model 0: torch.Size([1, 2])
Shape after model 1: torch.Size([1, 2])
Shape after model 2: torch.Size([1, 2])
Shape after model 3: torch.Size([1, 2])
Shape after model 4: torch.Size([1, 2])
Final output shape: torch.Size([1, 2])
Prediction shape: torch.Size([1, 2])
Probability: 0.4672005548117703
Prediction: False

Prediction completed
The prediction results have been saved to: ./phs002517_prediction.tsv
